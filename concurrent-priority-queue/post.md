# Конкурентная очередь с приоритетами

# Введение

Очередь с приоритетами - это абстрактный тип данных с 2 операциями: 
- Enqueue - Добавить элемент
- Dequeue - Извлечь элемент с минимальным/максимальным ключом
  
Обычно она реализуется с помощью кучи. Но это синхронная реализация. Что если нужна конкурентная работа?

# Конкурентные реализации

Попыток создать конкурентные реализации было несколько. 
В результате многие пришли к выводу, что лучшей структурой данных лежащей в основе, будет список с пропусками.

<spoiler title="Список с пропусками">
Список с пропусками - это вероятностная структура данных. Она основана на нескольких отсортированных связных списках.

Всего есть несколько слоев, причем первый это обычный *упорядоченный* связный список. А каждый следующий уровень - отдельный список, который может указывать на другие.

За счет рандомизации высоты каждого узла, можно достичь логарифмической сложности `O(log(N))`.

Важная деталь - на первом уровне все узлы расположены в порядке возрастания.

// TODO: добавить картинку изображения

</spoiler>

# Реализация 

При реализации конкурентной очереди с приоритетом в основе я использовал статью Linden and .. TODO: добавить ссылку на статью.

Моя реализация буквально слово в слово повторяет их, за исключением моментов: адаптации к C# и поддержки одинаковых ключей

## Основные структуры данных

Основной структурой является узел

```cs
// TODO: добавить код 
```

Сама очередь с приоритетами представляется таким образом

```cs
// TODO: добавить код
```

- Сказать что флаг нужен только для 1 уровня ???

## Enqueue

Первой операцией рассмотрим вставку нового элемента.
Механика вставки похожа на вставку в обычный список с пропусками. 

Эта операция делится на 2 части:
1. Вставка узла на 1 уровне
2. Наращивание высоты узла

### Вставка на 1 уровне

Вначале определяется место для вставки нового элемента.
Алгоритм такой же как и в обычном списке с пропусками:
1. Переходим на `i` уровень
2. Пропускаем все удаленные узлы
3. Пропускаем все узлы с ключами не больше, либо пока не наткнемся на хвост списка
4. Сохраняем 2 узла: на котором остановились и на который указывает этот узел на `i` уровне (между ними вставляем новый узел)

Повторяем так, пока не достигнем первого уровня.

```cs
// TODO: код GetInsertLocation
```

В результате у нас есть 2 массива: `predecessors` и `successors` - предшествующие и последующие узлы для нового узла,
`i`-ый элемент которых указывает на предшествующий или последующий узел на `i` высоте

// TODO: картинка с логикой вставки и визуализацией элементов массивов

Далее, когда нам нужно будет вставить элемент на уровне `i` после предшествующего узла, нужно сравнить узел на который он указывает на `i` уровне с хранящимся элементом у нас (`successors[i]`)

Когда эти массивы получены вставляем элемент на первом уровне через `CAS`.
В случае, если операция провалилась - повторяем этот этап заново, так как список был изменен (в частности, перед предшественником на 1 уровне параллельно вставили узел)

```cs
// TODO: код вставки
```

### Наращивание высоты

Когда узел был успешно добавлен в список, переходим ко 2 этапу - наращивание высоты. 
Начиная с этого момента, вставляемый узел является полноценным членом списка, поэтому в любой момент может быть удален, либо около него вставлены элементы.

Наращивание высоты происходит так же как и в обычном списке с пропусками снизу вверх (за исключением проверок):
1. Переходим к очередному уровню `i`
2. Проверяем, что узел не удален
3. На новом узле выставляем ссылку на следующий узел на высоте `i` 
4. Атомарно (`CAS`) меняем ссылку на следующий узел у предшествующего узла с проверкой на равенство нашему последователю 
5. Если обмена не произошло, то 
   1. Вычисляем предшествующие и последующие узлы заново 
   2. Если предшествующий узел не равен добавляемому, то прекратить алгоритм

На шаге 2 мы делаем 2 проверки: 
- Следующий сразу после нас узел не удален
- Последующие узлы на каждом уровне не удалены

Обе они проверяют, что узлы *после* нас не удалены - проверки, что *вставляемый* узел удален не делаем.
Такая проверка исходит из того, что флаг удаления хранится в предыдущем узле и перед нами может в любой момент быть вставлен новый узел.

В оригинальной статье предполагалось наличие различных ключей, поэтому на этапе 5.2 проверялось равенство с последующим узлом. Я немного изменил алгоритм (добавил поддержку различных ключей), поэтому новые элементы с одинаковыми ключами добавляются после старых элементов. 
Может случиться и так, что добавился новый узел с одинаковым ключом, но наш узел еще не до конца добавлен. Я принял решение прекращать добавление новых узлов, так как это проще реализовать. 

```cs
// TODO: код вставки
```

## Dequeue

Удаление тоже разделено на 2 части: логическое и физическое.

### Логическое удаление

Логическое удаление - выставление флага удаления `NextDeleted`. 
Для логического удаления итерируются все узлы на первом уровне, пока не найдется тот, у которого следующий узел не удален.
Когда такой найден, выставляется флаг, и удаленным считается *следующий узел*.

В оригинальной статье, этот флаг хранился в наименьшем значащем бите указателя на первом уровне (`Successors[0]`).

В 32-х битных системах это будут 2 бита, а в 64-х битных - 3. 
Часто так и поступают (используют LSB в качестве флагов), но:
- В управляемых языках (C#, Java, Python) нет возможности прямого управления указателями
- В word-aligned архитектурах нет LSB в указателях - все место заполнено

Для решения этой проблемы я выделил флаг удаления в отдельное поле `NextDeleted` и, чтобы выполнить логическое удаление, беру блокировку.
В качестве блокировки использую `SpinLock`. Под капотом он использует `Interlocked.CompareExchange`, и так как при захваченной блокировке выполняется только простая проверка с присвоением (сложной логики нет), то (грубо) все действия можно заменить на один `CAS`.

```cs
// TODO: код
```

### Физическое удаление

Физическое удаление - очищение памяти. В случае управляемого языка, это значит просто удалить все указатели на удаленные узлы, а GC сам очистит память.
Для оптимизации физическое удаление происходит батчами, т.е. при достижении определенного количества логически удаленных узлов.

Все логически удаленные узлы формируют префикс и таким образом список можно разделить на 2 части: 
- Префикс удаленных узлов
- Список с живыми узлами с неубывающими ключами

Удаление так же выполняется с помощью `CAS` - старый первый узел меняется новым. 
Причем новый первый узел должен быть также удаленным, т.е. после первого удаления голова списка всегда будет указывать на удаленный узел. 
Это нужно для того 

```cs
// TODO: код
```

# Бенчмарки

Теперь настало время сравнения производительности.
Для сравнения я использовал очередь с приоритетом из стандартной библиотеки `System.Collections.Generic.PriorityQueue`. 
Она реализована с помощью 4-арной кучей (вместо 2 потомков - 4). Разбор реализации есть в (этой статье)[https://habr.com/ru/companies/skbkontur/articles/666018/]

Предварительно я добавил пулинг массивов `successors` и `predecessors` при вставке нового элемента.

Параметризация тестов нескольких видов:
- Количество потоков: 1, 2, 4, 6, 8, 10
- Стратегия добавляемых ключей: случайные, возрастающие, убывающие
- Стратегия выполнения операций: вставка/удаления поочередно; сначала вставка всех элементов, затем удаление
- Количество элементов для добавления: 100000, 500000

Тесты проводились на ноутбуке:
- AMD Ryzen 5 
- 16 Гб RAM


Результаты представлены на графиках

// TODO: добавить графики

Как видно: моя конкурентная реализация сильно уступает версии с глобальной блокировкой.

Даже когда заменил инстанциирование новых массивов `Successors` на пуллинг, а в версии с глобальной блокировкой заменил `SpinLock`  на `lock` практически ничего не поменялось: даже худшее исполнение глобальной блокировки было лучше конкурентной версии кратно.

# Вывод

Оказалось версия с глобальной блокировкой сильно обгоняет конкурентную версию. 
Причиной этому я вижу:
- Большие накладные расходы на поиск места вставки нового узла и его постоянные вычисления
- Расходы на аллокации памяти для новых узлов

В оригинальной статье приводилось сравнение с другими, уже существующими *конкурентными* реализациями, но сравнения с синхронной под блокировкой не было. Зато она была в статье ... и там, версия Linden сильно обгоняла все остальные. 
Из этого я делаю вывод, что проблема скорее всего из-за моей неправильной реализации.

А пока я не нашел ответа "почему так?" предлагаю использовать обертку с глобальной блокировкой.

