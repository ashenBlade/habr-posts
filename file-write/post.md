# Как писать в файлы?

Содержание:
1. Уровни какие проходит запрос записи
2. Системный вызов/ОС
3. Файловая система
4. Диск
5. А как же рантайм
    - трансляция запросов
    - Рассказать про баг .NET 7
6. Выводы

# Введение

Приветствую. 

TODO: ... Про пет-проект ...

Данные приложения я храню на диске, в файле. Казалось бы, просто вызови `write` и дождись окончания записи.
Но немного исследовав эту тему, я понял, что не все так просто - существует большое количество подводных камней, которые надо учитывать, чтобы быть немного уверенным, что данные точно сохранены.

Для начала представим путь, который проходят данные, перед тем как быть записанными на диск:

TODO: блоки визуализации (Приложение -> ОС -> Файловая система -> Диск).

# Приложение

Зависит от языка какие вызовы нужно сделать
Есть буферризация
Привести примеры различных ЯП
А еще стандартную библиотеку C (как пример)
Ну и мой пример

Тут про fflush, Flush у BufferedStream (C#) и даже когда открывается файл, то внутри есть BufferedStrategy

Как защититься/что делать: зависит от ЯП

---
Все начинается с самого приложения. 
Обычно у нас имеется интерфейс для работы с файлами. Это зависит от ЯП, но примеры:
- `fwrite` - C
- `std::fstream.write` - C++
- `FileStream.Write` - C#
- `FileOutputStream.Write` - Java
- `open().write` - Python
- `File.Write` - GO

и другие.

Это все средства предоставляемые языками программирования, для работы с файлами: запись, чтение и т.д.
Их преимуществом является независимость от платформы, на которой мы работаем. 
Но также и привносит свои недостатки. 
В данном случае, это буферизация.

Судя по документации, то из приведенных выше все ЯП используют либо поддерживают буферизацию:
- C - [setvbuf](https://en.cppreference.com/w/c/io/setvbuf)
- C++ - [filebuf](https://cplusplus.com/reference/fstream/filebuf/)
- C# - [BufferedFileStrategy](https://github.com/dotnet/runtime/blob/main/src/libraries/System.Private.CoreLib/src/System/IO/Strategies/BufferedFileStreamStrategy.cs)
- Java - [Files.newBufferedReader](https://docs.oracle.com/javase/8/docs/api/java/nio/file/Files.html#newBufferedWriter-java.nio.file.Path-java.nio.charset.Charset-java.nio.file.OpenOption...-)
- Python - [io.BufferedIOBase](https://docs.python.org/3/library/io.html#io.BufferedIOBase)
- GO - [bufio.Reader](https://pkg.go.dev/bufio#Reader)

> Насчет C# - в реализации `FileStream` используется `FileStreamStrategy` класс, который обрабатывает запросы. 
> Например, при создании `FileStream` через `File.Open`, `BufferedFileStrategy` обертывает целевой `OSFileStreamStrategy`.

Вообще, буферизация в пространстве пользователя штука неплохая, так как позволяет повысить производительность. 
Но если не знать этого, то часть данных может быть не записана.
Тут может быть 2 случая:
1. Буферизованный файл создан вручную (GO, Java).
2. Буферизация происходит прозрачно для программиста (C, C++).

Если в первом случае мы точно знаем, что буферы надо сборосить после окончания записи, то второй вариант позволит выстрелить себе в ногу:
- Приложение экстренно закроется (например, получили SIGKILL нельзя обработать) и буферы уровня приложения просто не сбросятся.
- Файл после создания будет где-то в памяти и при закрытии буферы сброшены не будут, т.к. просто забудем сделать это.

Выходов здесь 2:
- Сбрасывать буферы после каждого сеанса записи. 
  Например, при логировании мы сначала всю пачку строк записываем через `write` и, только когда все были записаны сбрасываем буфер.
- Убрать буферизацию вообще и делать записи напрямую.

На мой взгляд, более привлекательный вариант - первый. 
Так как он позволит немного повысить производительность.

Для сравнения производительности я провел небольшой бенчмарк.

Записал последовательно в файл 64 Мб данных.
Тестирование производил на 2 машинах:
- Личный ноутбук: NVMe
- Старый сервер: HDD

Результаты следующие:

| Машина | Прямая запись, мс | Буферизированная запись, мс | 
|--------|-------------------|-----------------------------|
| Личный | 75.77             | 62.06                       |
| Старая | 122.1             | 104.9                       |

Как видно, разница заметна: время выполнения при буферизации меньше примерно в 1.2 раза.

<spoiler title="Код бенчмарка">

```cs
TODO: добавить код
```

</spoiler>

# ОС

Язык программирования дает хорошую абстракцию платформы - разработчику не нужно думать (как минимум, не так часто) на какой операционной системе работает приложение.
Но в любом случае функции языка будут транслироваться/превращаться в системные вызовы ОС, для записи в файлы.
Эти системные вызовы специфичны для каждой операционной системы, но в общем случае всегда есть для записи, чтения и открытия файлов.
Например, вот примерное отображение:

| Операция | *nix  | Windows   |
|----------|-------|-----------|
| Открытие | open  | OpenFile  |
| Чтение   | read  | ReadFile  |
| Запись   | write | WriteFile |
| Закрытие | close | CloseFile |

> Под *nix имеют Unix-подобные ОС (Linux, FreeBSD, OSX). 
> Название у этих вызовов одинаковые, хоть и поведение немного отличается.

На уровне ОС тоже присутствует буферизация - [страничный (дисковый) кэш](https://en.wikipedia.org/wiki/Page_cache).
И вот с помощью нее выстрелить в ногу еще проще. 

При работе с файлом (чтение/запись) данные из него читаются страницами, даже когда запрошен только 1 байт (записать или прочитать). 
Когда страница была изменена, то она называется "грязной" и будет сброшена на диск. 
Причем в памяти одновременно может находиться множество страниц, они и создают страничный кэш - буфер уровня ОС.

Так где это может нам повредить? Представим следующий процесс:
1. Нам пришел запрос на обновление данных о пользователе;
2. Мы открываем файл с данными;
3. Переписываем имеющийся диапазон имени переданным значением (представим, что для имени выделено в файле 255 символов);
4. Сообщаем пользователю, что имя успешно обновлено.

Где может возникнуть проблема? После 4 шага. Просто представим, что после отправки ответа пользователю об успешно выполненной операции произошло отключение электричества.
В результате имеем такую ситуацию:
- Пользователь думает, что имя успешно обновлено.
- Данные о пользователе хранятся старые.

Почему старые? Потому что перезаписанное имя хранилось на грязной странице в памяти, а не на диске, и при отключении электричества мы ее сохранить не успели.

Страничный кэш полезен, когда над одним участком памяти производится множество операций чтения/записи. 
Но в случае, когда изменения должны быть "закоммичены" нам нужно удостовериться, что записанные данные действительно были сброшены на диск.
Для этого можно применить несколько стратегий:
1. Системные вызовы для сброса буферов;
2. При открытии файла говорить сразу, что буферизация не нужна.

## Системные вызовы для сброса страниц 

Первый вариант использует специальные системные вызовы.
Для Linux можно использовать:
- `fdatasync(fd)` - проверяет, что данные в памяти и на диске синхронизированы, т.е. выполняет сброс страниц и при необходимости обновляет размер файла;
- `fsync(fd)` - то же самое что и `fdatasync`, но дополнительно синхронизирует метаданные файла (время доступа, изменения и др.);
- `sync_file_range(fd, range)` - проверяет, что указанный диапазон данных файла сброшен на диск;
- `sync()` - эта функция тоже синхронизирует содержимое буферов и дисков, только делает это для всех файлов, а не указанного.

Как уже было сказано, `fdatasync` синхронизирует только содержимое, без метаданных как `fsync`, поэтому он выполняется быстрее.


> Больше про эти системные вызовы описано в статье [Устойчивое хранение данных и файловые API Linux](https://habr.com/ru/companies/ruvds/articles/524172/).

Для Windows это:
- `_commit` - сбрасывает данные файла прямо на диск;
- `FlushFileBuffers(fd)` - вызывает запись всех буферных данных в файл (я не Windows разработчик, поэтому не знаю точно чем отличается от предыдущего вызова);
- `NtFlushBuffersFileEx(fd, params)` - сброс страниц на диск, но только для файловых систем NT (NTFS, ReFS, FAT, exFAT).

P.S. `NtFlushBuffersFileEx` [используется в Postgres](https://github.com/postgres/postgres/blob/874d817baa160ca7e68bee6ccc9fc1848c56e750/src/port/win32fdatasync.c#L40) как обертка для кроссплатформенного `fdatasync`.

## Говорим ОС, что синхронизация не нужна

Для второго варианта, нам необходимо открывать файл с необходимым параметром.

В Linux это можно сделать передав параметры `O_SYNC | O_DIRECT` функции `open` при открытии файла.
- `O_SYNC` говорит о том что `write` не должен возвращаться, пока данные не будут точно записаны на диск. Есть еще `O_DSYNC` - это про синхронизацию только данных, без метаданных;
- `O_DIRECT` говорит о том что для записи не нужно использовать страницы, т.е. запись будет происходить в обход страничного кэша.

Использование флага `O_SYNC`/`O_DSYNC` можно сравнить с тем, что после каждого write будет вызываться `fsync`/`fdatasync`, соответственно.

После открытия файла, с помощью `fcntl` можно изменить только `O_DIRECT` флаг, но не `O_SYNC`. Это прописано в описании `fcntl`:
> ... It is not possible to change the O_DSYNC and O_SYNC flags; see BUGS, below.

В Windows для этого есть свои аналоги: флаги `FILE_FLAG_NO_BUFFERING` и `FILE_FLAG_WRITE_THOUGH` для функции открытия файла `CreateFile`:
- `FILE_FLAG_NO_BUFFERING` - отключает буферизацию при записи. Аналог `O_DIRECT`; 
- `FILE_FLAG_WRITE_THOUGH` - каждая запись сразу сбрасывается на диск. Аналог `O_SYNC`;

В [документации](https://learn.microsoft.com/en-us/windows/win32/api/fileapi/nf-fileapi-createfilea#caching-behavior) дано описание поведению при указании обоих флагов:
> If FILE_FLAG_WRITE_THROUGH and FILE_FLAG_NO_BUFFERING are both specified, so that system caching is not in effect, then the data is immediately flushed to disk without going through the Windows system cache. The operating system also requests a write-through of the hard disk's local hardware cache to persistent media.

## Синхронизация директорий

Но это еще не все. 
Вспомним, что 1) файлы создаются, удаляются и перемещаются и 2) директории - тоже файлы. 
То есть при изменении содержимого директории, ее содержимое должно быть сброшено на диск так же как и файл.

В *nix выполняется это точно так же, как и с файлами - получаем дескриптор директории и выполняем `fsync(directory_fd)` на нее.
Это поведение также задокументированно:

> Calling  fsync() does not necessarily ensure that the entry in the directory containing the file has also reached disk. 
> For that an explicit fsync() on a file descriptor for the directory is also needed.

P.S. Я искал информацию о том, можно ли избежать ручного вызова `fsync` для директории через указание флага `O_SYNC`, но ничего не нашел. 
Если знаете, влияет ли этот флаг на работу с директориями, то подскажите в комментариях. 

Что же касается Windows, то там это сделать нельзя:
1. Директорию нельзя открыть - при попытке происходит ошибка `EACCESS`;
2. `FlushFileBuffers` работает только с файлами, либо томом (все файлы тома сбросить), но для последнего нужны повышенные привилегии.

Это поведение должно учитывать и в Postgres это тоже [проверяется](https://github.com/postgres/postgres/blob/874d817baa160ca7e68bee6ccc9fc1848c56e750/src/backend/storage/file/fd.c#L3797):
```c++
/*
 * fsync_fname_ext -- Try to fsync a file or directory
 *
 * If ignore_perm is true, ignore errors upon trying to open unreadable
 * files. Logs other errors at a caller-specified level.
 *
 * Returns 0 if the operation succeeded, -1 otherwise.
 */
int
fsync_fname_ext(const char *fname, bool isdir, bool ignore_perm, int elevel)
{
	/*
	 * Some OSs require directories to be opened read-only whereas other
	 * systems don't allow us to fsync files opened read-only; so we need both
	 * cases here.  Using O_RDWR will cause us to fail to fsync files that are
	 * not writable by our userid, but we assume that's OK.
	 */
	flags = PG_BINARY;
	if (!isdir)
		flags |= O_RDWR;
	else
		flags |= O_RDONLY;

	/*
	 * Some OSs don't allow us to open directories at all (Windows returns
	 * EACCES), just ignore the error in that case.  If desired also silently
	 * ignoring errors about unreadable files. Log others.
	 */
	if (fd < 0 && isdir && (errno == EISDIR || errno == EACCES))
		return 0;
	else if (fd < 0 && ignore_perm && errno == EACCES)
		return 0;
	else if (fd < 0)
	{
		ereport(elevel,
				(errcode_for_file_access(),
				 errmsg("could not open file \"%s\": %m", fname)));
		return -1;
	}

	returncode = pg_fsync(fd);

	/*
	 * Some OSes don't allow us to fsync directories at all, so we can ignore
	 * those errors. Anything else needs to be logged.
	 */
	if (returncode != 0 && !(isdir && (errno == EBADF || errno == EINVAL)))
	{
		// ...
		return -1;
	}

	return 0;
}
```

## Ошибки fsync

`fsync` _может_ вернуть ошибку и ее необходимо обработать. 
Это было показано в примере выше.
Если она вернула ошибку, то единственное допустимое действие - завершение работы.
Почему? 
Потому, что после этого мы **не можем быть уверены** в том, что сам **файл остался в согласованном состоянии**, даже если с точки зрения файловой системы он не поломан (об этом будет дальше),
- Файловая система может быть повреждена;
- В файле может появиться дыра (неправильная запись);
- Грязные страницы для записи могут быть помечены чистыми и больше сброшены не будут. 

Последнее может привести к тому, что файл на диске и в памяти имеют разное содержимое, но заметно этого не будет. 

Для справедливости стоит сказать, что пометка страниц чистыми - это часть реализации Linux, так как он предполагает, что файловая система возьмет на себя обязательства корректно закончить операции. 
Вот [тут](https://wiki.postgresql.org/wiki/Fsync_Errors#Research_notes_and_OS_differences) есть примеры поведения различных ОС при ошибке `fsync` (что происходит со страницами):
- Darwin/macOS - отбрасываются;
- OpenBSD - отбрасываются;
- NetBSD - отбрасываются;
- FreeBSD - остаются грязными;
- Linux (после 4.16) - помечаются чистыми;
- Windows - неизвестно.

Можно привести пример, когда некорректное управление этими ошибками приводило к потерям данных - сохранение данных WAL в Postgres.
Изначально, разработчики базы данных предполагали, что семантика `fsync` следующая: 

> Если `fsync()` выполнился успешно, то все записи с момента последнего _успешного_ `fsync` были сброшены на диск.

Т.е. если мы сейчас вызвали `fsync` и он вернул ошибку, то мы можем просто повторить этот вызов в будующем в надежде, что данные в итоге попадут на диск.
Но это ошибочное предположение. 
В реальности, если `fsync` вернул ошибку, то грязные страницы будут просто "забыты", т.е. семантика:

> Если `fsync()` выполнился успешно, то все записи с момента последнего ~~успешного~~ `fsync` были сброшены на диск.

Т.е. все ошибки синхронизации данных с диском просто игнорировались. 
Это было замечено в 2018 году и вопрос поднялся в [списке рассылки](https://lwn.net/Articles/752093/).
Багу даже дали название `fsyncgate 2018` и посвятили отдельную страницу на [вики](https://wiki.postgresql.org/wiki/Fsync_Errors).
Сам баг исправлен в версии 12 (и во многих предыдущих) в [этом коммите](https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=9ccdd7f66e3324d2b6d3dec282cfa9ff084083f1) и если быть точным, то исправили следующим образом:

```c++
// fd.c
int
data_sync_elevel(int elevel)
{
    return data_sync_retry ? elevel : PANIC;
}

// Любая функция
void sample_function() 
{
    // Любой вызов fsync в логике 
    if (pg_fsync(fd) != 0)
    // ereport(ERROR,
       ereport(data_sync_elevel(ERROR),
                (errcode_for_file_access(),
                 errmsg("could not fsync file \"%s\": %m", path)));
}
```

<spoiler title="Страничный кэш в БД">

Работа с диском - важная часть любой базы данных. Поэтому многие реализуют свою систему работы со страничным кэшэм и не полагаются на механизмы ОС.
Благодаря этому:
- Более эффективный IO, т.к. запись на диск производится только после `COMMIT`; 
- Используются (потенциально) более оптимальные алгоритмы замещения страниц;
- Размер страницы и их количество в памяти может настраиваться;
- Безопасность работы с данными;

Вот примеры некоторых СУБД:

| СУБД           | Реализация                                                                                                                                                                                                                                                             | Где почитать                                                                                                                                 | Алгоритм замещения страниц |
|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|----------------------------|
| Postgres       | [bufmgr.h](https://github.com/postgres/postgres/blob/d13ff82319ccaacb04d77b77a010ea7a1717564f/src/include/storage/bufmgr.h), [bufmgr.c](https://github.com/postgres/postgres/blob/d13ff82319ccaacb04d77b77a010ea7a1717564f/src/backend/storage/buffer/bufmgr.c)        | [WAL в PostgreSQL: 1. Буферный кеш](https://habr.com/ru/companies/postgrespro/articles/458186/)                                              | clock-sweep                |
| SQL Server     | Исходников не нашел                                                                                                                                                                                                                                                    | [Обзор компонентов управления памятью в SQL Server](https://habr.com/ru/articles/233365/)                                                    | LRU-2 (LRU-K)              |
| Oracle         | Исходников не нашел                                                                                                                                                                                                                                                    | [Oracle Memory Architecture](https://www.appservgrid.com/documentation111/docs/rdbms10g/windows/doc/server.101/b10743/memory.htm#sthref1252) | LRU, Temperature-based     |
| MySQL (InnoDB) | [buf0buf.h](https://github.com/mysql/mysql-server/blob/824e2b4064053f7daf17d7f3f84b7a3ed92e5fb4/storage/innobase/include/buf0buf.h), [buf0buf.cc](https://github.com/mysql/mysql-server/blob/824e2b4064053f7daf17d7f3f84b7a3ed92e5fb4/storage/innobase/buf/buf0buf.cc) | [InnoDB Buffer Pool](https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html)                                                        | LRU                        |

Как уже было сказано, собственный менеджер буферов позволяет оптимизировать работу СУБД, поэтому многие разработчики не останавливаются на единственном "умном" алгоритме замещения страниц. Примеры:
- ORACLE и SQL Server имеет возможность использовать flash накопители в качестве временного хранения буферов, вместо сброса на основной диск (параметр `DB_FLASH_CACHE_FILE` для Oracle и расширение Buffer Pool для SQL Server);
- Postgres позволяет "разогревать" кэш страниц с помощью расширения `pg_prewarm`;

</spoiler>

# Файловая система

Данные так-то хранятся хоть на диске, но в файловой системе, которая сложна по устройству (метаданные, битовая карта, чанки данных).

Журналирование - один из основных способов сохранения согласованности. 
Поможет, но есть переупорядочивание (как в модели памяти - атомарность и переупорядочивание) (ссылку на сашу гольдштейна с выстплением про модели памяти).

Разные ФС дают разные гарантии и имеют разные семантики (исследование Not All Filesystems created equal).
Привести примеры переупорядочиваний.

Привести примеры различных файловых систем и их настроек. Возможно найти рейтинг используемых файловых систем.

Как защититься: лог операций свой, чек-суммы, мусор проверять на старте, тюнить параметры ФС.

Кейс: как правильно писать в файл с учетом мусора и т.д. (Files Are Hard вольный пересказ)

Про LVM поискать что нибудь.


## Переупорядочивание

TODO: переупорядочивание лучше на сторону ФС оставить

Представим, что нам нужно создать файл с критичными данными. Для большей безопасности мы решили сначала создать временный файл и после переименовать его, чтобы другие процессы его пока не видели.
Реализовали таким образом:
```c++
void initialize_very_important_file() 
{
    int fd = open("temp_file", O_RDWR | O_CREAT);
    write(fd, initial_data_1);
    write(fd, initial_data_2);
    rename("temp_file", "critical_file");
    close(fd);
}
```

Обычно работает нормально, но однажды запустив приложение - все крашнулось. Причина - некорректно инициализированный файл.
В чем причина? Переупорядочивание IO операций.
ОС может изменять порядок вызова



# Диск

Данные хранятся на каком-то постоянном хранилище и могут сломаться.
Для хранения могут использоваться HDD, SSD, NVMe, Сетевое хранилище (NFS, облако), Магнитная лента.

Вот тут наши данные и хранятся.
Только если они были повреждены

Атомарность записи в сектор и Powersafe Overwrite

Как защититься: RAID, fsck, бэкапы

https://www.evanjones.ca/durability-nvme.html
Про SSD: https://kcall.co.uk/ssd/index.html

Вроде бы все, но нет. Мы забыли о, пожалуй, главном.

## Про SQLite

Предположения:
- запись в сектор не атомарна, но линейна (начало записи с края, но не с середины сектора);
- размер сектора для read и write может быть разным (для flash это так), но опираемся только на write размерj;
- ОС будет буферизировать ввод и переупорядочивать операции записи - поэтому в ключевых моментах `flush`/`fsync`
- Знают, что `fsync` может быть сломан, но сделать с этим ничего не могут;
- Размер файла обновляется перед записью новых данных - может быть мусор в конце.
- Удаление файла атомарна с точки зрения пользовательского процесса - т.е. либо полностью сохранился, либо полностью удален (без изменений данных файла);
- Обнаружение и исправление ошибок в файлах (плохие биты и т.д.) - на стороне оборудования и пользователя, никаких доп. действий SQLite не делает для починки.
- Предполагают PowerSafe OverWrite (PSOW) по умолчанию

Как может БД пострадать:
- Сломанная реализация блокировок ОС
- `fsync`/`FlushFileBuffers` могут не работать: 1) на некоторых ФС это no-op, 2) может быть заблокирован реестром (???!!). + контроллер диска может солгать

# Среда выполнения

Многие приложения

Почему я заострил внимание - я нашел критичный (в этом контексте) баг .NET 7. Рассказать про найденный баг.

Возможно найти другие баги различных райнтаймов (Java, GO, Python, .NET).

`Поэтому важно ручками проверить, что этих багов нет. Но пожалуй самый радикальный способ - напрямую вызывать системные вызовы`.
Дать пример в C#

# Рецепты файловой записи

Тут пример undo/redo логов, атомарного rename

Вот тут пример с undo log и мой пример с рафтом и т.д.

## Как создавать или обновить инициализированный файл

Стоит еще и рассказать про один интересный паттерн создания файлов.

Представим, что нам нужно создать новый файл и при этом его нужно инициализировать каким-то содержимым.

Первая идея - создать новый файл и записать в него нужные значения.
Проблема здесь в неатомарности операции: создание файла и запись в него данных. Машина может отключиться прямо в середине записи в файл и тогда в файле может быть только половина содержимого.
Это не проблема, если файл новый, - просто начать заново. Но что если нам нужно перезаписать существующий файл?

Чтобы понять как это решить, посмотрим на часть документации к `rename`:

> If `newpath` already exists, it will be atomically replaced, so that there is no point at which another process attempting to access `newpath` will find it missing.

Т.е. `rename` атомарная операция и если мы хотим изменить часть содержимого файла, либо создать готовый, то:
1. Создаем временный файл
2. Записываем в него данные
3. Переименовываем файл в целевой - `rename`
4. Вызываем `fsync` для директории (не забываем)

Согласно этому [исследованию](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-pillai.pdf), такой подход используется в Git, Mercurial, LevelDB, HSQLDB, VMWare, HDFS.
Я нашел такой подход в [etcd](https://github.com/etcd-io/etcd/blob/e54bd67554fa2d57e882a6cc949cc90624fecb29/server/storage/wal/wal.go#L733) при создании нового сегмента лога:
```go
// cut closes current file written and creates a new one ready to append.
// cut first creates a temp wal file and writes necessary headers into it.
// Then cut atomically rename temp wal file to a wal file.
func (w *WAL) cut() error {
    // ... Закрытие старого конца 
	
	// create a temp wal file with name sequence + 1, or truncate the existing one
	newTail, err := w.fp.Open()

	// ... Записываем данные в новый сегмент - инициализируем

    // ... Атомарно переименовываем готовый файл сегмента
	// atomically move temp wal file to wal file
	if err = w.sync(); err != nil {
		return err
	}
	
	if err = os.Rename(newTail.Name(), fpath); err != nil {
		return err
	}
	
	// ... Вызываем fsync для директории с сегментами лога
	if err = fileutil.Fsync(w.dirFile); err != nil {
		return err
	}
    
    // ... Обновление внутреннего состояния приложения
}
```

В документации `rename` также прописано, что возможно существование окна, когда старый и новый пути указывают на файл, который собираемся переименовать.
Но так как мы своего добились - атомарно обновили содержимое файла, то в случае отказа просто останется старый временный файл (еще один hardlink), который просто надо удалить.

# Мой случай

Описать что использую сегментированный лог
Атомарность записи в сектор не волнует
Так как использую рафт, то 

# Заключение

Вроде бы простая задача - записать данные на диск, но слишком много подводных камней. 
Чтобы быть точно уверенным нужно учитывать множество факторов.

https://lwn.net/Articles/457667/