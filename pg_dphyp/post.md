# pg_dphyp

Содержание:

1. Контекст
   1. Основная задача планировщика - поиск join'ов
   2. Алгоритм зависит от подхода, но вот такие есть сегодня
   3. В PostgreSQL такой подход DPsize -> GEQO
   4. Как работает DPsize
   5. Для чего нужен GEQO
2. DPhyp
   1. Что это за алгоритм
   2. Кто использует (ссылку на ydb статью добавить)
   3. Ядро алгоритма (краткое описание)
   4. Не всегда оптимально - если все связны, то это обычный DPsize (надо подсчитывать кол-во связных подграфов)
   5. Закончить словами "а можно ли добавить в PostgreSQL? - Да можно"
3. pg_dphyp
   1. Что это и как работает (есть хук, который можно использовать)
   2. Описание реализации основные детали реализации
   3. Заканчиваю "Поиск соседей - это основа и надо ее оптимизировать" (или как-то так)
4. Оптимизация с перебором подмножеств соседей
   1. История с MySQL (в первой реализации) + их наблюдение что 20-70% - рассмотреть их реализацию
   2. GPLv2 зло - я ушел от этого
   3. Посмотрел на задачу под другим углом - MSB меняется реже чем LSB
   4. Первая идея - 2 слойный кэш (base часть и меняющаяся) - 8 Кб страница
   5. Вторая идея (сжать) - 3 слойный кэш (well-done/medium/rare) - 0.5 Кб (тут про even/odd оптимизацию, сжатие начала и т.д.)
   6. Третья идея - фиксированый кэш с подсчетом нулей
   7. Закуска - подсчет связных подграфов (из статьи)
5. Индексирование
   1. "А можно ли еще подшаманить? - Да можно"
   2. Наблюдение, что есть движущаяся и фиксированная части обхода ребер
   3. Когда обходим, то фиксированная часть может максимум увеличиться
   4. В начале задаем маску 'excluded' первые биты которой выставлены - они точно будут не нужны
   5. Сортируем массив ребер и создаем 'start_index'
   6. Для excluded - получаем этот бит, а для 'rhs' - `+-1` трюк
6. Другие особенности PostgreSQL
   1. "В отличие от ydb или mysql я делаю расширение под готовую БД, а не изменяю ядро существующей" - надо подстраиваться под БД
   2. Храню список `candidates`, т.к. все подстроено под этот стиль, а потом top-down прохожу
   3. Приходится находить ребра самостоятельно - извлекать из окружения (предикаты и т.д.) - сказать, что при обходе дерева и сбора время резко возрастает поэтому отказался
   4. Из-за этого не могу корректно обработать `CROSS JOIN` (но не отчаился и используют Union-Set алгоритм, сказать про GUC)
   5. Можно не заботиться о порядке следования таблиц (PG сам это сделает + initial_rels уже отсортирован)
7. Итоги
   1. Бенчмарков не проводил, но результаты сомнительные - где-то есть, а где-то нет улучшения
   2. PostgreSQL большую часть времени тратит на `make_join_rel` (флеймграф показать) - надо его сокращать
   3. Пробовал некоторые оптимизации:
      1. "принцип оптимальности" (сказать что это) не сработал (обрезал по стоимости найденные пути)
      2. Кодогенерированная DP таблица (но словил SEGFAULT, поэтому перешел на проверенный HTAB)
      3. Блум фильтр
   4. Сложно сказать на каких нагрузках может быть полезно расширение
   5. "Теперь я понял, что такое GPL и больше не буду его использовать - все распространяю под MIT"

## Планировщики запросов

Планировщик в базах данных это, пожалуй, самый сложный и важный компонент системы, особенно если мы говорим о терабайтах данных: неважно насколько быстрое железо стоит в серверной - если планировщик чуть-чуть ошибся и использует последовательное сканирование вместо индекса, то приходите за результатом через неделю. И в этом сложном компоненте можно выделить ядро - перебор JOIN'ов. То, как мы собираемся это (перебор) делать и определяет ~~наш лагерь~~ архитектуру планировщика: top-down или bottom-up.

Судить о них проще всего если представить граф запроса. Например, вот такой запрос:

```sql
SELECT t1.y, MIN(t2.y)
FROM t1 JOIN (
        SELECT t3.x x, MAX(t4.y) y
        FROM t3 JOIN t4 ON t3.x = t4.x
    ) t2 ON t1.x = t2.x
    WHERE t2.y > 10;
```

Имеет такой граф запроса:

### TODO

Top-down подход - это подход сверху вниз (еще называют goal-oriented, ориентированный на цель). Мы заходим в корень, понимаем его "цель" (есть ли группировка/фильтрация, что на выходе и т.д.) и на основании этого создают план запроса. Преимуществом такого подхода является то, что у нас на руках полный контекст и мы можем его использовать.
Примером может служить планировщик (грубо говоря, это архитектура) cascades, который используется в MS SQL Server.

Bottom-up - это противоположный лагерь, где вначале планируют все JOIN'ы, а только потом навешивают сортировку/группировку и другие операторы.
Этот подход используются во многих базах данных, например, в том же самом PostgreSQL.
Преимуществом этого подхода является масштабируемость, так как он позволяет планировать огромное количество JOIN'ов, например, в статье [Adaptive Optimization of Very Large Join Queries](https://db.in.tum.de/~radke/papers/hugejoins.pdf) представляется подход, который комбинируя несколько разных алгоритмов позволяет выполнять планирование запросов с несколькими тысячами таблиц. Примером кто так делает в статье указывается SAP, который из-за постоянного использования представлений внутри других представлений может создать запрос использующий тысячи обычных таблиц.

Сейчас мы акцентируем внимание на последнем подходе, а именно на используемых алгоритмах. Но этих алгоритмов довольно много, поэтому вначале рассмотри алгоритмы, используемые в PostgreSQL.

## DPsize

Во времена рассвета РСУБД никто не понимал, как это все должно работать и делали кто как знал. Тогда и появился первый алгоритм динамического программирования для поиска порядка соединений. Сегодня все (как минимум в статьях) обращаются к нему как `DPsize`.

> Для начала простое определение, что такое отношение. РСУБД построена на работе с отношениями и по факту это просто источник данных со своей схемой (атрибутами). Таблица - это самый простой пример отношения. Но другой важный сейчас пример - это `JOIN`, т.к. по факту он отвечает требованиям (дает кортежи и есть атрибуты). Далее, я буду говорить именно "отношение", а где это важно, то "таблица".

Его идея довольно проста - чтобы создать JOIN из `i` таблиц отношений нужно соединить другие отношения, которые в сумме количества таблиц дадут этот `i`. Например, для `4` нам нужно соединить: `1` и `3`, `2` и `2`. Собственно, это и есть динамическое программирование - ответ текущего шага зависит от ответа прошлых, ну а базой выступают отношения размера `1`, то есть обычные таблицы. Этот алгоритм неплохо себя показывает на OLTP нагрузке и дает практически оптимальные планы запросов, но проблемы начинаются когда таблиц становится слишком много.

Как можете заметить, сложность этого алгоритма экспоненциальная, так как на каждом следующем шаге нам предстоит обработать еще больше пар отношений. Разные базы данных борются с этим по разному, но в PostgreSQL пошли путем использования другого алгоритма.

## GEQO

GEQO, Genetic Query Optimizer - это генетический алгоритм поиска оптимального плана запроса. Если вы попробуете запустить в PostgreSQL запрос сначала на 12 таблиц, а после на 13, то удивитесь, что затраченное время снизилось с нескольких секунд, до почти *десяти миллисекунд*. Почему?

Ответ прост - это рандомизированный алгоритм. Его работу можно описать просто: вначале строим хоть какой-нибудь план запроса, а затем проводим несколько итераций (определяется конфигурацией), в каждой из которых случайно меняем какие-нибудь узлы, и в следующую итерацию идет план с лучшей стоимостью. Честно говоря, я не разбираюсь в GEQO, чтобы что-то утверждать, и не видел много людей, разбирающихся в нем.

# TODO: прочитать про GEQO

## DPhyp

Переходим к основной теме - DPhyp.

DPhyp - это алгоритм динамического программирования для перебора JOIN'ов. Его основная идея заключается в том, что сам запрос содержит указания того, как должно происходить соединение таблиц. Так почему-бы его не использовать? Ну, основная проблема в самом представлении запроса. Ранее, я оговорился, что запрос можно представить в виде графа, но можно ли так сделать для целей перебора JOIN'ов? Чтобы понять в чем трудность посмотрим на пример из статьи:

```sql
SELECT *
FROM t1, t2, t3, t4, t5, t6
WHERE t1.x = t2.x AND t2.x = t3.x AND t4.x = t5.x AND t5.x = t6.x AND
      t1.x + t2.x + t3.x = t4.x + t5.x + t6.x
```

Да, мы видим, что есть несколько *явно* соединенных между собой таблиц - для них мы можем создать ребра в нашем графе (например, `t1 - t2`), но что делать с последним предикатом, который по факту соединяет множества таблиц?

Эту проблему и решает DPhyp - алгоритм динамического программирования, основанных на *гиперграфах* (hyp - hypergraph).

Пугаться не стоит, все довольно просто. Для начала, предполагаю, что вы знакомы с обычным графом - множество, соединенных между собой ребрами узлов. Гиперграф - это множество гиперузлов, соединенных между собой гиперребрами:

- гиперузел (hypernode) - это *множество* обычных узлов
- гиперребро (hyperedge) - это ребро, *соединяющее 2 гиперузла*

В запросе из примера у нас имеются следующие гиперребра:

1. `{t1} - {t2}`
2. `{t2} - {t3}`
3. `{t4} - {t5}`
4. `{t5} - {t6}`
5. `{t1, t2, t3} - {t4, t5, t6}`

Если в гиперузле только 1 отношение, то его называют простым гиперузлом. Аналогично, если гиперребро соединяет 2 простых гиперузла, то это простой гиперузел - первые 4 это простые гиперребра.

В итоге, чтобы создать план для множества из `i` узлов нам нужно обойти уже не все возможные пары, дающие `i` в сумма, а все пары гиперузлов, которые в объединении дают тоже множество. Такая пара - это пара из 2-ух непересекающихся множеств `connected subgraph` (csg, подграф) и `connected complement` (cmp, дополнение) - эти аббревиатуры вы увидите еще не раз.

Но не все так просто и чтобы это заработало оптимально требуется небольшое ограничение - порядок узлов. Над узлами (т.е. таблицами) должно быть отношение порядка, грубо говоря, они должны быть пронумерованы (что используется чаще всего). Чтобы понять зачем рассмотрим ядро алгоритма - соседство.

В процессе работы алгоритма, чтобы переходить от одного гиперузла к другому мы используем соседей (neighborhood). В статье дается и математическое определение, но проще всего сказать, что соседи для какого-либо гиперузла - это множество других достижимых узлов. Также требуется, чтобы это множество было минимальным, в противном случае мы будем обрабатывать одни и те же гиперузлы несколько раз. Вот тут и нужен порядок - когда обходим ребра для нахождения соседей, то в множество добавляем только *представителя* гиперузла, его *минимальный элемент*. Дальше нам нужно просто проверить, что другие ребра не содержат уже добавленные узлы.

И последняя важная деталь алгоритма - исключенное множество (excluded set). В DPsize в качестве оптимизации итерирование по дополняющим парам мы начинаем не с 0, а со следующего индекса, или в противном случае попытаемся соединить себя с собой же. Здесь примерно та же идея - мы ведем учет узлов, которые не стоит рассматривать (исключенные) и учитываем это практически везде (даже при нахождении соседей). Исключаем узлы для того, чтобы не рассматривать одно и то же множество дважды.

Основная логика алгоритма в статье представлена в виде 4 функций, но вкратце можно описать так: нам нужно найти csg-cmp пару, которая в объединении дает весь запрос, поэтому с помощью поиска соседей будет поочередно/рекурсивно увеличивать csg и cmp. Вопрос только в том, а с чего начать? На это ответ тоже простой - мы начинаем итерироваться по всем узлам *начиная с конца*, а при дальнейшем вызове в *excluded* записываем все узлы, которые меньше текущего. В итоге, мы начинаем с простого гиперузла, который никто не рассматривал и затем рекурсивно его расширяем/находим cmp для него с помощью соседей.

Собственно, теперь все готово, чтобы понять функции:

- `Solve` - входная точка алгоритма, просто итерируемся по простым гиперузлам с конца и вызываем `EmitCsg` и `EnumerateCsgRecursive`
- `EmitCsg` - принимает уже *фиксированный* csg, для которого находит подходящий cmp, а затем вызывает `EmitCsgCmp` и/или `EnumerateCmpRecursive`
- `EmitCsgRecursive` - принимает csg, который расширяет с помощью соседей, затем вызывает `EmitCsg` и/или `EnumerateCsgRecursive`
- `EnumerateCmpRecursive` - принимает *фиксированный* csg и cmp, с помощью соседей расширяет cmp, затем вызывает `EmitCsgCmp` и/или `EnumerateCmpRecursive`
- `EmitCsgCmp` - создает готовый план для *фиксированных* csg и cmp

В общем, это все. Основная идея алгоритма довольно проста и понятна. В качестве примера в статье также есть иллюстрация работы алгоритма для запроса из примера:

# TODO: скриншот

---

Алгоритм хороший, так почему бы не добавить его в PostgreSQL? Можно? Можно и всегда было! Для это и существует `join_search_hook`, который позволяет подменить алгоритм перебора JOIN'ов. Собственно, дальше мой рассказ.

## pg_dphyp

Идея для создания этого расширения пришла ко мне спонтанно. Я изучал разные алгоритмы JOIN'ов и наткнулся на него. Немного поискав в интернете я не нашел ничего для PostgreSQL и понял, что надо сделать самому. Кому уже сразу хочется посмотреть на то, что получилось [вот ссылка на репозиторий](https://github.com/ashenBlade/pg_dphyp).

В контексте ядра работы алгоритма я не принес ничего нового, даже наоборот - больше копипастил у других. Перед тем как приступить к реализации своего, я посмотрел реализации нескольких СУБД. В частности посмотрел на YDB, MySQL и DuckDB. Если кто хочет изучить DPhyp по коду, то рекомендую посмотреть на [код YDB](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_dphyp_solver.h) - код чистый и понятный, очень легко читать. Но сам я начал не с YDB, а с MySQL.

В реализации я старался быть ближе к статье и делать минимальное количество изменений. В частности, название функций и некоторых переменных тоже самое, что и в статье. Об этом я говорю, т.к. смотрел на код MySQL - они много что переименовали у себя и сразу разобраться не получиться, только по комментариям. Например, функцию `EmitCsg` они [назвали `EnumerateComlementsTo`](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L351) или [`forbidden` вместо `excluded`](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L210). Это конечно тоже корректно, никто не запрещает, то приступить к коду сложнее.

Но хоть, как я сказал, в ядре алгоритма отличий нет, они есть на уровне принятия операционных решений. Первое решение, которое надо принять - это представление множеств.

### Представление множеств

Множества являются лошадкой алгоритма, поэтому эффективность всей программы зависит от эффективности этого атома.

Разные СУБД делают это по разному. Например, DuckDB [использует числа напрямую и хранит их в массиве](https://github.com/duckdb/duckdb/blob/73f85abbbdd38555ef7afa08090dfb4b10120df8/src/include/duckdb/optimizer/join_order/join_relation.hpp#L24), [YDB - `std::bitset<>`](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_join_cost_based.cpp#L341), а [MySQL простое 8-байтное число](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/node_map.h#L40).

Кто работает с PostgreSQL знает, что там имеется [своя реализация - `Bitmapset`](https://github.com/postgres/postgres/blob/62a47aea1d8d8ea36e63fe6dd3d9891452a3f968/src/include/nodes/bitmapset.h#L49). Она используется повсеместно и часто для хранения ID отношений. Вроде бы бери раз дают, но проблема в том, что операций над множествами огромное количество, а `Bitmapset` создает новую копию каждый раз когда меняется, то есть это лишние аллокации памяти. В PostgreSQL эта проблема часто не возникает, так как после создания `Bitmapset` он редко меняется, но в моем случае это критично.

Эту проблему я решил выбрав 2 стула сразу - создал 2 файла где в 1 использовал `bitmapword` (8 байтное число, как в MySQL), а в другом `Bitmapset`. Но это произошло в самом начале разработки, когда я еще не особо понимал как работает алгоритм и его тонкости, поэтому через некоторое время на файл с `Bitmapset` забил (решил добавить изменения позже), а потом вообще удалил. В итоге, сейчас я использую представление множества с помощью числа, а точнее битовой карты.

Проблем это не доставляет. Основные операции с множеством выполняются простыми битовыми `|`, `&` и `~`. Но есть и еще пара операций, которая важна для самого алгоритма. Например, итерирование по элементам множества (например, для вычисления соседей). Таких операций много, поэтому я вынес их в отдельный [заголовочный файл](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/simplebms.h).

Другая интересная операция - итерирование по всем подмножествам. Это нужно для расширения csg/cmp. Так как множество это число, то и операция проводится с числом. В MySQL это решили с помощью битового трюка `(init - state) & state`, который при постоянном применении ведет себя как инкремент, но при этом изменяются только биты множества. Эту реализацию я [взял себе](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L584).

### DP таблица

DPhyp - это алгоритм динамического программирования и у него есть своя таблица для отслеживания состояния выполнения.

Если посмотреть на алгоритм из статьи, то видно, что эта таблица используется только для хранения готовых планов. В PostgreSQL за готовые планы (представление отношения) используется структура `RelOptInfo` и *она уже хранится в хэш-таблице*. Вроде вот и хорошо - не надо думать о создании своей, но нет.

Проблема заключается уже в самом PostgreSQL, а точнее его обработке `FULL JOIN`. Для этого типа соединений сейчас поддерживается только предикат равенства, а в коде, когда встречается такой предикат, все отношения в левой и правой части попадают в отдельные списки, которые планируются *независимо*. Это причина по которой, для внутренних таблиц используется своя система индексации (то есть индексы узлов DPhyp не обязательно соответствуют индексам отношений). Поэтому даже если я буду на время превращать `bitmapword` в `Bitmapset` (что потребует еще выделения памяти), то не смогу этого сделать, если индексы отношений больше 64 (максимального значения для 8-байтного числа).

Поэтому для алгоритма используется своя DP таблица. По факту, это хэш-таблица - `HTAB *`, часть PostgreSQL. Особенность этой таблицы в том, что в ней хранится только 1 структура, а ее ключ должен хранится в начале этой структуры. Из-за этого была добавлена еще 1 структура `HyperNode`, которая представляет гиперузел. Но сейчас это просто пара из множества узлов и отношения - в ней хранятся и другие данные.

### Построение графа

Другая не менее важная задача - это построение самого графа. Проблема в том, что в отличие от YDB или MySQL, балом я не правлю и должен подстраиваться под саму БД.

С одной стороны, проблемы вроде нет - я могу пройтись по всем предикатам, используемым в запросе и из них создать ребра. Собственно, сейчас это так и реализуется. Но дьявол кроется в деталях.

Для начала - эту информацию мне приходится брать из 3 различных мест:

1. `RelOptInfo->joinclauses` - список из предикатов, которые используют больше 1 отношения, то есть по факту это JOIN условие.
2. `PlannerInfo->join_info_list` - список из non-INNER JOIN условий
3. `PlannerInfo->eq_classes` - список классов эквивалентности (далее)

Самое простое - [это 2](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1627). Этот список содержит ограничения, которые накладывают разные non-INNER (т.е. LEFT/RIGHT/FULL и т.д.) JOIN'ы. В нем есть 2 пары частей: синтаксические ограничения и минимальные (нужны для непосредственного вычисления). На всякий случай, я создаю гиперребро для обеих пар.

Про остальные тоже надо сказать. [Первое](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1536) имеет сложности с точки зрения *самого выражения* - оно может и не быть бинарным, а может быть, но по обеим сторонам используется одно и то же отношение. Для таких моментов я добавил свое понятие - cross join set (cjs). По факту, это просто множество отношений, которые должны соединиться между собой. Для каждого отношения в cjs я создаю простые ребра (каждый с каждым). Это решает проблему того, что какие-то предикаты могут отсутствовать. DPsize (который по умолчанию в PostgreSQL) решает это за счет того, что обрабатывает каждую возможную пару, а алгоритм этого не предполагает.

Теперь 3 - [классы эквивалентности](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1561). Класс эквивалентности - это механизм PostgreSQL, с помощью которого он определяет, что какие-то выражения равны друг другу. Это используется не только в выражениях, например, выражения в `ORDER BY` или `GROUP BY` представляются именно классом эквивалентности (возможно вырожденным, с 1 элементом). Но сейчас не об этом, а том как это стреляет. Такие классы эквивалентности появляются, когда в запросе имеются выражения равенства, даже одного достаточно для создания класса эквивалентности. Как можно догадаться, они также используются для JOIN'ов. Когда я встречаю класс эквивалентности с несколькими отношениями, то приходится создавать гиперребра для каждой пары.

К сожалению, это не покрывает всех вариантов. Проблема кроется в 1. Во время работы PostgreSQL создает все возможные варианты выражения с разным набором необходимых отношений с левой и правой части. Это позволяет рассмотреть разные варианты расположения выражения в дереве. Проблема в том, что индексы отношений, которые там используются могут относится не к таблицам, а к индексам узлов JOIN (`RangeTblEntry` типа `RTE_JOIN`). Но я не нашел оптимального способа собрать все индексы таблиц по переданному индексу JOIN, и из-за этого теряю львиную долю гиперребер. Вы можете сказать "ну обойди дерево запроса и собери". Да я так и сделал - время планирования на сложных запросах увеличилось *совсем чуть-чуть* - с 500 мс до 16 секунд и это при том, что план остался тем же самым. Поэтому сейчас расширение дает не самые оптимальные планы запросов.

### Несвязные подграфы

Из предыдущего вытекает еще одна проблема. Что будет если мы получили несвязный граф (то есть лес)? В таком случае алгоритм ничего не сможет сделать. Точнее, он создаст план для каждого графа в лесу, но для запроса не сможет.

Причем эта проблема может вылиться не только из-за `CROSS JOIN` или `,`, но и из-за внешних параметров подзапросов. Приведу пример:

```sql
SELECT * FROM t1
WHERE t1.x IN 
    (SELECT t2.x FROM t2, t3 WHERE t2.x = t1.x AND t3.x = t1.x);
```

В этом подзапросе `t1.x` является параметром, но на выходе в графе у нас лес, потому что для `t1` в подзапросе нет индекса. Можно представить и более сложные запросы, которые могут упасть таким образом. Вообще, это я обнаружил, когда запустил `\d` (чтобы отобразить все таблицы) в `psql` и оказалось, что там был примерный запрос.

С одной стороны, на практике несвязные графы довольно редкое явление, чтобы тратить ресурсы для обнаружения этого, с другой, из-за подобного мы можем потратить лишнее время (просто удвоить время планирования без полезной нагрузки). Поэтому решение как поступать я отдал на откуп пользователям.

Имеется отдельная настройка `pg_dphyp.cj_strategy`, которая принимает 3 значения:

- `no` - если не смогли построить план, то вызвать DPsize/GEQO
- `pass` - если не смогли построить план, то собрать все готовые планы несвязных деревьев и отдать DPsize/GEQO на финальную доработку
- `detect` - создавать гиперребра для несвязных графов перед началом работы

Кажется, что первый вариант лишний, но на самом деле не особо, так как планы, созданные для этих подграфов могу быть не оптимальными из-за причины выше, поэтому и финальный план тоже может быть не оптимальным.

Остается вопрос - как находить несвязные графы. Ответ на поверхности - [Union-Set алгоритм](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L975). Для производительности я использую оптимизированную версию - с ранжированием и обновлением лидера у обоих частей.

### Хранение гиперребер

Еще одна задача - хранение гиперграфа.

Граф можно хранить в виде списка ребер, а можно таблицей смежности. Но для гиперграфа, остается только первый вариант, так как практически невозможно построить таблицу смежности для гиперребер.

Хорошо, определились, но можно ли применить какие-нибудь оптимизации? Да, можно. Почти у всех реализаций (например, [YDB](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_join_hypergraph.h#L84) и [MySQL](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/hypergraph.h#L69)) есть оптимизация для простых гиперребер. Напомню, что у простого гиперребра по обеим сторонам множества из единственного элемента. Эта оптимизация заключается в том, что мы храним все узлы, с которыми нас связывают простые гиперребра, в одном множестве. Далее, в процессе работы нам нужно сделать единственную операцию для проверки сразу нескольких ребер. Это часто называют `simple neighborhood`, почему, наверное, понятно.

Я тоже взял себе эту оптимизацию, но пошел чуть дальше и храню этот `simple neighborhood` для каждого `HyperNode`. Это немного упрощает работу, так как не нужно тратить время на дополнительное итерирование, а места занимает только 8 байт (множества представляю в виде чисел). Храню этот `simple neighborhood` в `HyperNode`, о котором говорил ранее.

А что по сложным (то есть не простым) гиперребрам? Тут тоже не без замечаний. Ранее я сказал, что для одного и того же выражения могут существовать несколько объектов выражения, но с разным набором индексов необходимых отношений. Тогда же я и сказал, что не могу эти дополнительные индексы обработать. Поэтому в результате я могу получить множество дубликатов.

С этим я решил бороться обычной [сортировкой](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1096) - все ребра я храню в отсортированном виде и если при вставке нахожу равное ребро, то ничего не делаю (не вставляю).

### Создание плана

Сама статья не только про алгоритм на гиперграфах, но также и про эффективное создание плана. Это важный момент, так как некоторые JOIN операторы не коммутативны (например, `LEFT JOIN`), и если это не учитывать, возможно придется вычислять одну и ту же пару дважды.

На данный момент, для меня это не особая проблема с точки зрения функциональности - я использую готовую функцию `make_join_rel`, которая за меня создаст план. Но в этом, возможно, и заключается еще одна проблема.

Заключается она в том, что время работы планировщика **слишком** большое, бывает даже больше времени DPsize. Если посмотрим на флейм-граф типичного запроса, то увидите, что все время съедает `make_join_rel`. Тоже самое увидите и для DPsize.

# TODO: svg с perf собрать

Но это еще не все. Напомню, что DPsize плотно засел в кодовой базе, да на столько, что нельзя создать план для `i` таблиц, без нахождения оптимального плана для нижележащих.

Изначально я так и делал - после создания плана вызывал `set_cheapest` для нахождения лучшего плана и дальше мог спокойно вызывать `make_join_rel` для других. Но если посмотреть внутрь, то увидите, что внутри эта функция проходит по всем найденным путям, то есть по мере работы программы время затраченное на ее выполнение будет только увеличиться.

Из-за этого я перешел на DPsize-like подход. Для каждого гиперузла я веду список пар гиперузлов, которые могут его создать, а затем в конце просто рекурсивно вызываю создание плана. Такой pull подход.
Да, есть вероятность, что внутри окажется пара, которая не сможет создать план запроса и я потрачу время впустую, но накладные расходы на изначальный подход все же больше, а тем более вероятность подобного крайне мала из-за DPhyp.

Но это проблема не PostgreSQL, а моя - не надо использовать функции DPsize внутри DPhyp, поэтому однажды возьмусь за написание своей логики создания плана.

## Оптимальное итерирование по подмножествам соседей


