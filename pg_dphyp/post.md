# pg_dphyp

Содержание:

1. Контекст
   1. Основная задача планировщика - поиск join'ов
   2. Алгоритм зависит от подхода, но вот такие есть сегодня
   3. В PostgreSQL такой подход DPsize -> GEQO
   4. Как работает DPsize
   5. Для чего нужен GEQO
2. DPhyp
   1. Что это за алгоритм
   2. Кто использует (ссылку на ydb статью добавить)
   3. Ядро алгоритма (краткое описание)
   4. Не всегда оптимально - если все связны, то это обычный DPsize (надо подсчитывать кол-во связных подграфов)
   5. Закончить словами "а можно ли добавить в PostgreSQL? - Да можно"
3. pg_dphyp
   1. Что это и как работает (есть хук, который можно использовать)
   2. Описание реализации основные детали реализации
   3. Заканчиваю "Поиск соседей - это основа и надо ее оптимизировать" (или как-то так)
4. Оптимизация с перебором подмножеств соседей
   1. История с MySQL (в первой реализации) + их наблюдение что 20-70% - рассмотреть их реализацию
   2. GPLv2 зло - я ушел от этого
   3. Посмотрел на задачу под другим углом - MSB меняется реже чем LSB
   4. Первая идея - 2 слойный кэш (base часть и меняющаяся) - 8 Кб страница
   5. Вторая идея (сжать) - 3 слойный кэш (well-done/medium/rare) - 0.5 Кб (тут про even/odd оптимизацию, сжатие начала и т.д.)
   6. Третья идея - фиксированый кэш с подсчетом нулей
   7. Закуска - подсчет связных подграфов (из статьи)
5. Индексирование
   1. "А можно ли еще подшаманить? - Да можно"
   2. Наблюдение, что есть движущаяся и фиксированная части обхода ребер
   3. Когда обходим, то фиксированная часть может максимум увеличиться
   4. В начале задаем маску 'excluded' первые биты которой выставлены - они точно будут не нужны
   5. Сортируем массив ребер и создаем 'start_index'
   6. Для excluded - получаем этот бит, а для 'rhs' - `+-1` трюк
6. Другие особенности PostgreSQL
   1. "В отличие от ydb или mysql я делаю расширение под готовую БД, а не изменяю ядро существующей" - надо подстраиваться под БД
   2. Храню список `candidates`, т.к. все подстроено под этот стиль, а потом top-down прохожу
   3. Приходится находить ребра самостоятельно - извлекать из окружения (предикаты и т.д.) - сказать, что при обходе дерева и сбора время резко возрастает поэтому отказался
   4. Из-за этого не могу корректно обработать `CROSS JOIN` (но не отчаился и используют Union-Set алгоритм, сказать про GUC)
   5. Можно не заботиться о порядке следования таблиц (PG сам это сделает + initial_rels уже отсортирован)
7. Итоги
   1. Бенчмарков не проводил, но результаты сомнительные - где-то есть, а где-то нет улучшения
   2. PostgreSQL большую часть времени тратит на `make_join_rel` (флеймграф показать) - надо его сокращать
   3. Пробовал некоторые оптимизации:
      1. "принцип оптимальности" (сказать что это) не сработал (обрезал по стоимости найденные пути)
      2. Кодогенерированная DP таблица (но словил SEGFAULT, поэтому перешел на проверенный HTAB)
      3. Блум фильтр
   4. Сложно сказать на каких нагрузках может быть полезно расширение
   5. "Теперь я понял, что такое GPL и больше не буду его использовать - все распространяю под MIT"

## Планировщики запросов

Планировщик в базах данных это, пожалуй, самый сложный и важный компонент системы, особенно если мы говорим о терабайтах данных: неважно насколько быстрое железо стоит в серверной - если планировщик чуть-чуть ошибся и использует последовательное сканирование вместо индекса, то приходите за результатом через неделю. И в этом сложном компоненте можно выделить ядро - перебор JOIN'ов. То, как мы собираемся это (перебор) делать и определяет ~~наш лагерь~~ архитектуру планировщика: top-down или bottom-up.

Судить о них проще всего если представить граф запроса. Например, вот такой запрос:

```sql
SELECT t1.y, MIN(t2.y)
FROM t1 JOIN (
        SELECT t3.x x, MAX(t4.y) y
        FROM t3 JOIN t4 ON t3.x = t4.x
    ) t2 ON t1.x = t2.x
    WHERE t2.y > 10;
```

Имеет такой граф запроса:

### TODO

Top-down подход - это подход сверху вниз (еще называют goal-oriented, ориентированный на цель). Мы заходим в корень, понимаем его "цель" (есть ли группировка/фильтрация, что на выходе и т.д.) и на основании этого создают план запроса. Преимуществом такого подхода является то, что у нас на руках полный контекст и мы можем его использовать.
Примером может служить планировщик (грубо говоря, это архитектура) cascades, который используется в MS SQL Server.

Bottom-up - это противоположный лагерь, где вначале планируют все JOIN'ы, а только потом навешивают сортировку/группировку и другие операторы.
Этот подход используются во многих базах данных, например, в том же самом PostgreSQL.
Преимуществом этого подхода является масштабируемость, так как он позволяет планировать огромное количество JOIN'ов, например, в статье [Adaptive Optimization of Very Large Join Queries](https://db.in.tum.de/~radke/papers/hugejoins.pdf) представляется подход, который комбинируя несколько разных алгоритмов позволяет выполнять планирование запросов с несколькими тысячами таблиц. Примером кто так делает в статье указывается SAP, который из-за постоянного использования представлений внутри других представлений может создать запрос использующий тысячи обычных таблиц.

Сейчас мы акцентируем внимание на последнем подходе, а именно на используемых алгоритмах. Но этих алгоритмов довольно много, поэтому вначале рассмотри алгоритмы, используемые в PostgreSQL.

## DPsize

Во времена рассвета РСУБД никто не понимал, как это все должно работать и делали кто как знал. Тогда и появился первый алгоритм динамического программирования для поиска порядка соединений. Сегодня все (как минимум в статьях) обращаются к нему как `DPsize`.

> Для начала простое определение, что такое отношение. РСУБД построена на работе с отношениями и по факту это просто источник данных со своей схемой (атрибутами). Таблица - это самый простой пример отношения. Но другой важный сейчас пример - это `JOIN`, т.к. по факту он отвечает требованиям (дает кортежи и есть атрибуты). Далее, я буду говорить именно "отношение", а где это важно, то "таблица".

Его идея довольно проста - чтобы создать JOIN из `i` таблиц отношений нужно соединить другие отношения, которые в сумме количества таблиц дадут этот `i`. Например, для `4` нам нужно соединить: `1` и `3`, `2` и `2`. Собственно, это и есть динамическое программирование - ответ текущего шага зависит от ответа прошлых, ну а базой выступают отношения размера `1`, то есть обычные таблицы. Этот алгоритм неплохо себя показывает на OLTP нагрузке и дает практически оптимальные планы запросов, но проблемы начинаются когда таблиц становится слишком много.

Как можете заметить, сложность этого алгоритма экспоненциальная, так как на каждом следующем шаге нам предстоит обработать еще больше пар отношений. Разные базы данных борются с этим по разному, но в PostgreSQL пошли путем использования другого алгоритма.

## GEQO

GEQO, Genetic Query Optimizer - это генетический алгоритм поиска оптимального плана запроса. Если вы попробуете запустить в PostgreSQL запрос сначала на 12 таблиц, а после на 13, то удивитесь, что затраченное время снизилось с нескольких секунд, до почти *десяти миллисекунд*. Почему?

Ответ прост - это рандомизированный алгоритм. Его работу можно описать просто: вначале строим хоть какой-нибудь план запроса, а затем проводим несколько итераций (определяется конфигурацией), в каждой из которых случайно меняем какие-нибудь узлы, и в следующую итерацию идет план с лучшей стоимостью. Честно говоря, я не разбираюсь в GEQO, чтобы что-то утверждать, и не видел много людей, разбирающихся в нем.

# TODO: прочитать про GEQO

## DPhyp

Переходим к основной теме - DPhyp.

DPhyp - это алгоритм динамического программирования для перебора JOIN'ов. Его основная идея заключается в том, что сам запрос содержит указания того, как должно происходить соединение таблиц. Так почему-бы его не использовать? Ну, основная проблема в самом представлении запроса. Ранее, я оговорился, что запрос можно представить в виде графа, но можно ли так сделать для целей перебора JOIN'ов? Чтобы понять в чем трудность посмотрим на пример из статьи:

```sql
SELECT *
FROM t1, t2, t3, t4, t5, t6
WHERE t1.x = t2.x AND t2.x = t3.x AND t4.x = t5.x AND t5.x = t6.x AND
      t1.x + t2.x + t3.x = t4.x + t5.x + t6.x
```

Да, мы видим, что есть несколько *явно* соединенных между собой таблиц - для них мы можем создать ребра в нашем графе (например, `t1 - t2`), но что делать с последним предикатом, который по факту соединяет множества таблиц?

Эту проблему и решает DPhyp - алгоритм динамического программирования, основанных на *гиперграфах* (hyp - hypergraph).

Пугаться не стоит, все довольно просто. Для начала, предполагаю, что вы знакомы с обычным графом - множество, соединенных между собой ребрами узлов. Гиперграф - это множество гиперузлов, соединенных между собой гиперребрами:

- гиперузел (hypernode) - это *множество* обычных узлов
- гиперребро (hyperedge) - это ребро, *соединяющее 2 гиперузла*

В запросе из примера у нас имеются следующие гиперребра:

1. `{t1} - {t2}`
2. `{t2} - {t3}`
3. `{t4} - {t5}`
4. `{t5} - {t6}`
5. `{t1, t2, t3} - {t4, t5, t6}`

Если в гиперузле только 1 отношение, то его называют простым гиперузлом. Аналогично, если гиперребро соединяет 2 простых гиперузла, то это простой гиперузел - первые 4 это простые гиперребра.

В итоге, чтобы создать план для множества из `i` узлов нам нужно обойти уже не все возможные пары, дающие `i` в сумма, а все пары гиперузлов, которые в объединении дают тоже множество. Такая пара - это пара из 2-ух непересекающихся множеств `connected subgraph` (csg, подграф) и `connected complement` (cmp, дополнение) - эти аббревиатуры вы увидите еще не раз.

Но не все так просто и чтобы это заработало оптимально требуется небольшое ограничение - порядок узлов. Над узлами (т.е. таблицами) должно быть отношение порядка, грубо говоря, они должны быть пронумерованы (что используется чаще всего). Чтобы понять зачем рассмотрим ядро алгоритма - соседство.

В процессе работы алгоритма, чтобы переходить от одного гиперузла к другому мы используем соседей (neighborhood). В статье дается и математическое определение, но проще всего сказать, что соседи для какого-либо гиперузла - это множество других достижимых узлов. Также требуется, чтобы это множество было минимальным, в противном случае мы будем обрабатывать одни и те же гиперузлы несколько раз. Вот тут и нужен порядок - когда обходим ребра для нахождения соседей, то в множество добавляем только *представителя* гиперузла, его *минимальный элемент*. Дальше нам нужно просто проверить, что другие ребра не содержат уже добавленные узлы.

И последняя важная деталь алгоритма - исключенное множество (excluded set). В DPsize в качестве оптимизации итерирование по дополняющим парам мы начинаем не с 0, а со следующего индекса, или в противном случае попытаемся соединить себя с собой же. Здесь примерно та же идея - мы ведем учет узлов, которые не стоит рассматривать (исключенные) и учитываем это практически везде (даже при нахождении соседей). Исключаем узлы для того, чтобы не рассматривать одно и то же множество дважды.

Основная логика алгоритма в статье представлена в виде 4 функций, но вкратце можно описать так: нам нужно найти csg-cmp пару, которая в объединении дает весь запрос, поэтому с помощью поиска соседей будет поочередно/рекурсивно увеличивать csg и cmp. Вопрос только в том, а с чего начать? На это ответ тоже простой - мы начинаем итерироваться по всем узлам *начиная с конца*, а при дальнейшем вызове в *excluded* записываем все узлы, которые меньше текущего. В итоге, мы начинаем с простого гиперузла, который никто не рассматривал и затем рекурсивно его расширяем/находим cmp для него с помощью соседей.

Собственно, теперь все готово, чтобы понять функции:

- `Solve` - входная точка алгоритма, просто итерируемся по простым гиперузлам с конца и вызываем `EmitCsg` и `EnumerateCsgRecursive`
- `EmitCsg` - принимает уже *фиксированный* csg, для которого находит подходящий cmp, а затем вызывает `EmitCsgCmp` и/или `EnumerateCmpRecursive`
- `EmitCsgRecursive` - принимает csg, который расширяет с помощью соседей, затем вызывает `EmitCsg` и/или `EnumerateCsgRecursive`
- `EnumerateCmpRecursive` - принимает *фиксированный* csg и cmp, с помощью соседей расширяет cmp, затем вызывает `EmitCsgCmp` и/или `EnumerateCmpRecursive`
- `EmitCsgCmp` - создает готовый план для *фиксированных* csg и cmp

В общем, это все. Основная идея алгоритма довольно проста и понятна. В качестве примера в статье также есть иллюстрация работы алгоритма для запроса из примера:

# TODO: скриншот

---

Алгоритм хороший, так почему бы не добавить его в PostgreSQL? Можно? Можно и всегда было! Для это и существует `join_search_hook`, который позволяет подменить алгоритм перебора JOIN'ов. Собственно, дальше мой рассказ.

## pg_dphyp

Идея для создания этого расширения пришла ко мне спонтанно. Я изучал разные алгоритмы JOIN'ов и наткнулся на него. Немного поискав в интернете я не нашел ничего для PostgreSQL и понял, что надо сделать самому. Кому уже сразу хочется посмотреть на то, что получилось [вот ссылка на репозиторий](https://github.com/ashenBlade/pg_dphyp).

В контексте ядра работы алгоритма я не принес ничего нового, даже наоборот - больше копипастил у других. Перед тем как приступить к реализации своего, я посмотрел реализации нескольких СУБД. В частности посмотрел на YDB, MySQL и DuckDB. Если кто хочет изучить DPhyp по коду, то рекомендую посмотреть на [код YDB](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_dphyp_solver.h) - код чистый и понятный, очень легко читать. Но сам я начал не с YDB, а с MySQL.

В реализации я старался быть ближе к статье и делать минимальное количество изменений. В частности, название функций и некоторых переменных тоже самое, что и в статье. Об этом я говорю, т.к. смотрел на код MySQL - они много что переименовали у себя и сразу разобраться не получиться, только по комментариям. Например, функцию `EmitCsg` они [назвали `EnumerateComlementsTo`](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L351) или [`forbidden` вместо `excluded`](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L210). Это конечно тоже корректно, никто не запрещает, то приступить к коду сложнее.

Но хоть, как я сказал, в ядре алгоритма отличий нет, они есть на уровне принятия операционных решений. Первое решение, которое надо принять - это представление множеств.

### Представление множеств

Множества являются лошадкой алгоритма, поэтому эффективность всей программы зависит от эффективности этого атома.

Разные СУБД делают это по разному. Например, DuckDB [использует числа напрямую и хранит их в массиве](https://github.com/duckdb/duckdb/blob/73f85abbbdd38555ef7afa08090dfb4b10120df8/src/include/duckdb/optimizer/join_order/join_relation.hpp#L24), [YDB - `std::bitset<>`](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_join_cost_based.cpp#L341), а [MySQL простое 8-байтное число](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/node_map.h#L40).

Кто работает с PostgreSQL знает, что там имеется [своя реализация - `Bitmapset`](https://github.com/postgres/postgres/blob/62a47aea1d8d8ea36e63fe6dd3d9891452a3f968/src/include/nodes/bitmapset.h#L49). Она используется повсеместно и часто для хранения ID отношений. Вроде бы бери раз дают, но проблема в том, что операций над множествами огромное количество, а `Bitmapset` создает новую копию каждый раз когда меняется, то есть это лишние аллокации памяти. В PostgreSQL эта проблема часто не возникает, так как после создания `Bitmapset` он редко меняется, но в моем случае это критично.

Эту проблему я решил выбрав 2 стула сразу - создал 2 файла где в 1 использовал `bitmapword` (8 байтное число, как в MySQL), а в другом `Bitmapset`. Но это произошло в самом начале разработки, когда я еще не особо понимал как работает алгоритм и его тонкости, поэтому через некоторое время на файл с `Bitmapset` забил (решил добавить изменения позже), а потом вообще удалил. В итоге, сейчас я использую представление множества с помощью числа, а точнее битовой карты.

Проблем это не доставляет. Основные операции с множеством выполняются простыми битовыми `|`, `&` и `~`. Но есть и еще пара операций, которая важна для самого алгоритма. Например, итерирование по элементам множества (например, для вычисления соседей). Таких операций много, поэтому я вынес их в отдельный [заголовочный файл](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/simplebms.h).

Другая интересная операция - итерирование по всем подмножествам. Это нужно для расширения csg/cmp. Так как множество это число, то и операция проводится с числом. В MySQL это решили с помощью битового трюка `(init - state) & state`, который при постоянном применении ведет себя как инкремент, но при этом изменяются только биты множества. Эту реализацию я [взял себе](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L584).

### DP таблица

DPhyp - это алгоритм динамического программирования и у него есть своя таблица для отслеживания состояния выполнения.

Если посмотреть на алгоритм из статьи, то видно, что эта таблица используется только для хранения готовых планов. В PostgreSQL за готовые планы (представление отношения) используется структура `RelOptInfo` и *она уже хранится в хэш-таблице*. Вроде вот и хорошо - не надо думать о создании своей, но нет.

Проблема заключается уже в самом PostgreSQL, а точнее его обработке `FULL JOIN`. Для этого типа соединений сейчас поддерживается только предикат равенства, а в коде, когда встречается такой предикат, все отношения в левой и правой части попадают в отдельные списки, которые планируются *независимо*. Это причина по которой, для внутренних таблиц используется своя система индексации (то есть индексы узлов DPhyp не обязательно соответствуют индексам отношений). Поэтому даже если я буду на время превращать `bitmapword` в `Bitmapset` (что потребует еще выделения памяти), то не смогу этого сделать, если индексы отношений больше 64 (максимального значения для 8-байтного числа).

Поэтому для алгоритма используется своя DP таблица. По факту, это хэш-таблица - `HTAB *`, часть PostgreSQL. Особенность этой таблицы в том, что в ней хранится только 1 структура, а ее ключ должен хранится в начале этой структуры. Из-за этого была добавлена еще 1 структура `HyperNode`, которая представляет гиперузел. Но сейчас это просто пара из множества узлов и отношения - в ней хранятся и другие данные.

### Построение графа

Другая не менее важная задача - это построение самого графа. Проблема в том, что в отличие от YDB или MySQL, балом я не правлю и должен подстраиваться под саму БД.

С одной стороны, проблемы вроде нет - я могу пройтись по всем предикатам, используемым в запросе и из них создать ребра. Собственно, сейчас это так и реализуется. Но дьявол кроется в деталях.

Для начала - эту информацию мне приходится брать из 3 различных мест:

1. `RelOptInfo->joinclauses` - список из предикатов, которые используют больше 1 отношения, то есть по факту это JOIN условие.
2. `PlannerInfo->join_info_list` - список из non-INNER JOIN условий
3. `PlannerInfo->eq_classes` - список классов эквивалентности (далее)

Самое простое - [это 2](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1627). Этот список содержит ограничения, которые накладывают разные non-INNER (т.е. LEFT/RIGHT/FULL и т.д.) JOIN'ы. В нем есть 2 пары частей: синтаксические ограничения и минимальные (нужны для непосредственного вычисления). На всякий случай, я создаю гиперребро для обеих пар.

Про остальные тоже надо сказать. [Первое](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1536) имеет сложности с точки зрения *самого выражения* - оно может и не быть бинарным, а может быть, но по обеим сторонам используется одно и то же отношение. Для таких моментов я добавил свое понятие - cross join set (cjs). По факту, это просто множество отношений, которые должны соединиться между собой. Для каждого отношения в cjs я создаю простые ребра (каждый с каждым). Это решает проблему того, что какие-то предикаты могут отсутствовать. DPsize (который по умолчанию в PostgreSQL) решает это за счет того, что обрабатывает каждую возможную пару, а алгоритм этого не предполагает.

Теперь 3 - [классы эквивалентности](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1561). Класс эквивалентности - это механизм PostgreSQL, с помощью которого он определяет, что какие-то выражения равны друг другу. Это используется не только в выражениях, например, выражения в `ORDER BY` или `GROUP BY` представляются именно классом эквивалентности (возможно вырожденным, с 1 элементом). Но сейчас не об этом, а том как это стреляет. Такие классы эквивалентности появляются, когда в запросе имеются выражения равенства, даже одного достаточно для создания класса эквивалентности. Как можно догадаться, они также используются для JOIN'ов. Когда я встречаю класс эквивалентности с несколькими отношениями, то приходится создавать гиперребра для каждой пары.

К сожалению, это не покрывает всех вариантов. Проблема кроется в 1. Во время работы PostgreSQL создает все возможные варианты выражения с разным набором необходимых отношений с левой и правой части. Это позволяет рассмотреть разные варианты расположения выражения в дереве. Проблема в том, что индексы отношений, которые там используются могут относится не к таблицам, а к индексам узлов JOIN (`RangeTblEntry` типа `RTE_JOIN`). Но я не нашел оптимального способа собрать все индексы таблиц по переданному индексу JOIN, и из-за этого теряю львиную долю гиперребер. Вы можете сказать "ну обойди дерево запроса и собери". Да я так и сделал - время планирования на сложных запросах увеличилось *совсем чуть-чуть* - с 500 мс до 16 секунд и это при том, что план остался тем же самым. Поэтому сейчас расширение дает не самые оптимальные планы запросов.

### Несвязные подграфы

Из предыдущего вытекает еще одна проблема. Что будет если мы получили несвязный граф (то есть лес)? В таком случае алгоритм ничего не сможет сделать. Точнее, он создаст план для каждого графа в лесу, но для запроса не сможет.

Причем эта проблема может вылиться не только из-за `CROSS JOIN` или `,`, но и из-за внешних параметров подзапросов. Приведу пример:

```sql
SELECT * FROM t1
WHERE t1.x IN 
    (SELECT t2.x FROM t2, t3 WHERE t2.x = t1.x AND t3.x = t1.x);
```

В этом подзапросе `t1.x` является параметром, но на выходе в графе у нас лес, потому что для `t1` в подзапросе нет индекса. Можно представить и более сложные запросы, которые могут упасть таким образом. Вообще, это я обнаружил, когда запустил `\d` (чтобы отобразить все таблицы) в `psql` и оказалось, что там был примерный запрос.

С одной стороны, на практике несвязные графы довольно редкое явление, чтобы тратить ресурсы для обнаружения этого, с другой, из-за подобного мы можем потратить лишнее время (просто удвоить время планирования без полезной нагрузки). Поэтому решение как поступать я отдал на откуп пользователям.

Имеется отдельная настройка `pg_dphyp.cj_strategy`, которая принимает 3 значения:

- `no` - если не смогли построить план, то вызвать DPsize/GEQO
- `pass` - если не смогли построить план, то собрать все готовые планы несвязных деревьев и отдать DPsize/GEQO на финальную доработку
- `detect` - создавать гиперребра для несвязных графов перед началом работы

Кажется, что первый вариант лишний, но на самом деле не особо, так как планы, созданные для этих подграфов могу быть не оптимальными из-за причины выше, поэтому и финальный план тоже может быть не оптимальным.

Остается вопрос - как находить несвязные графы. Ответ на поверхности - [Union-Set алгоритм](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L975). Для производительности я использую оптимизированную версию - с ранжированием и обновлением лидера у обоих частей.

### Хранение гиперребер

Еще одна задача - хранение гиперграфа.

Граф можно хранить в виде списка ребер, а можно таблицей смежности. Но для гиперграфа, остается только первый вариант, так как практически невозможно построить таблицу смежности для гиперребер.

Хорошо, определились, но можно ли применить какие-нибудь оптимизации? Да, можно. Почти у всех реализаций (например, [YDB](https://github.com/ydb-platform/ydb/blob/c23202bc294cf703741f1ea6ac30786578a58920/ydb/library/yql/dq/opt/dq_opt_join_hypergraph.h#L84) и [MySQL](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/hypergraph.h#L69)) есть оптимизация для простых гиперребер. Напомню, что у простого гиперребра по обеим сторонам множества из единственного элемента. Эта оптимизация заключается в том, что мы храним все узлы, с которыми нас связывают простые гиперребра, в одном множестве. Далее, в процессе работы нам нужно сделать единственную операцию для проверки сразу нескольких ребер. Это часто называют `simple neighborhood`, почему, наверное, понятно.

Я тоже взял себе эту оптимизацию, но пошел чуть дальше и храню этот `simple neighborhood` для каждого `HyperNode`. Это немного упрощает работу, так как не нужно тратить время на дополнительное итерирование, а места занимает только 8 байт (множества представляю в виде чисел). Храню этот `simple neighborhood` в `HyperNode`, о котором говорил ранее.

А что по сложным (то есть не простым) гиперребрам? Тут тоже не без замечаний. Ранее я сказал, что для одного и того же выражения могут существовать несколько объектов выражения, но с разным набором индексов необходимых отношений. Тогда же я и сказал, что не могу эти дополнительные индексы обработать. Поэтому в результате я могу получить множество дубликатов.

С этим я решил бороться обычной [сортировкой](https://github.com/ashenBlade/pg_dphyp/blob/0cdc5b410d3bce41398a6646c576cca77994b6e3/pg_dphyp.c#L1096) - все ребра я храню в отсортированном виде и если при вставке нахожу равное ребро, то ничего не делаю (не вставляю).

### Создание плана

Сама статья не только про алгоритм на гиперграфах, но также и про эффективное создание плана. Это важный момент, так как некоторые JOIN операторы не коммутативны (например, `LEFT JOIN`), и если это не учитывать, возможно придется вычислять одну и ту же пару дважды.

На данный момент, для меня это не особая проблема с точки зрения функциональности - я использую готовую функцию `make_join_rel`, которая за меня создаст план. Но в этом, возможно, и заключается еще одна проблема.

Заключается она в том, что время работы планировщика **слишком** большое, бывает даже больше времени DPsize. Если посмотрим на флейм-граф типичного запроса, то увидите, что все время съедает `make_join_rel`. Тоже самое увидите и для DPsize.

# TODO: svg с perf собрать

Но это еще не все. Напомню, что DPsize плотно засел в кодовой базе, да на столько, что нельзя создать план для `i` таблиц, без нахождения оптимального плана для нижележащих.

Изначально я так и делал - после создания плана вызывал `set_cheapest` для нахождения лучшего плана и дальше мог спокойно вызывать `make_join_rel` для других. Но если посмотреть внутрь, то увидите, что внутри эта функция проходит по всем найденным путям, то есть по мере работы программы время затраченное на ее выполнение будет только увеличиться.

Из-за этого я перешел на DPsize-like подход. Для каждого гиперузла я веду список пар гиперузлов, которые могут его создать, а затем в конце просто рекурсивно вызываю создание плана. Такой pull подход.
Да, есть вероятность, что внутри окажется пара, которая не сможет создать план запроса и я потрачу время впустую, но накладные расходы на изначальный подход все же больше, а тем более вероятность подобного крайне мала из-за DPhyp.

Но это проблема не PostgreSQL, а моя - не надо использовать функции DPsize внутри DPhyp, поэтому однажды возьмусь за написание своей логики создания плана.

## Оптимальное итерирование по соседям

Наконец-то мы пришли к самой интересной части - как мы будем обходить соседей. В алгоритме можно выделить 3 функции, которые заняты перебором пар csg/cmp и в них нам нужно вычислять соседей целых 4 раза (на 3 функции). Все становится страшнее, когда осознаешь, что алгоритм предполагает итерирование по всем возможным подмножествам соседей ([power set](https://en.wikipedia.org/wiki/Power_set) без пустого множества) - это $2^i$ комбинаций.

Да, мы добавили оптимизацию простого соседства (simple neighborhood) и даже кэшируем, но все же нам необходимо обработать все узлы и полученных подмножествах (кроме того, есть и основная часть, к которой это подмножество добавляется - для него тоже надо посчитать) - это $\sum_{k = 1}^{n}kC_{n}^{k}$.

Свое путешествие я начал с рассмотрения кода MySQL. Они серьезно подошли к алгоритму и, можно сказать, написали свой, потому что в некоторых местах их код явно отходит от самого DPhyp. Например, при вызове `EnumerateCsgRec` (их версия - `ExpandSubgraph`) для `EmitCsg` они вычисляют соседей, но соседи вычисляются не с тем исключенным множеством, что и в статье. Для их реализации это наверное, вполне корректно и, может, они обрабатывают это дальше - не знаю, но первое время я очень много смотрел на их код и удивлялся, почему ничего не сходится.

Но, хоть их код и сильно отличается от того, что в статье, он довольно полезен с инженерной точки зрения. В их коде довольно много комментариев, которыми они описывают те или иные принятые решения (чаще всего на основании микробенчмарков). Один из [таких комментариев](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L280) написан к функции вычисления соседей:

> ...
> This function accounts for roughly 20–70% of the total DPhyp running time, depending on the shape of the graph (~40% average across the microbenchmarks)
> ...


Для того, чтобы ускорить вычисление соседей они используют кэширование по подмножествам.

### Подход в MySQL

Их идея построена на свойстве подмножеств, которые мы получаем при итерировании. Напомню, что они используют битовый трюк, каждый раз прибавляют 1 и таким образом обходят все подмножества.

Если посмотреть на это повнимательнее, то можно заметить, что при таком подходе при следующем шаге мы получим подмножество предыдущего шага. В частности, последний бит постоянно переключается то в `0`, то в `1`. А если последний бит переключить из `0` в `1`, то мы получим подмножество!

Сразу возникает желание просто взять предыдущих соседей и довычислить этим последним битом, но возникает вопрос - а корректно ли это? Да, корректно. Если еще раз взглянем на определение соседей, то не увидим там порядка обхода узлов, а это значит, что мы можем взять одно множество и дополнить еще каким-нибудь узлом.

Чтобы стала понятна идея рассмотрим на примере итерации по подмножеству из 4 узлов. Буквально привожу пример из их комментария:

```text
0001
0010 *
0011
0100 *
0101
0110 *
0111
1000 *
1001
1010 *
1011
1100 *
1101
1110 *
1111
```

Звездочкой я указал места, в которых нам придется полностью вычислять соседей, то есть вымывать кэш, но после этого нам будет достаточно обработать только 1 узел (первый). Если все делать честно, то для исходного множества размера 4 придется обрабатывать 32 узла, а с помощью этой эвристики только 20.

Из их комментария также становится понятно, что существуют оптимальные порядки обхода подмножеств, которые дадут еще больший прирост. Для тех же 4 он будет таким (в комментарии в коде, наверное очепятка, поэтому здесь моя поправленная версия):

```text
0001 
0010 *
0011 
0100 *
0101
0110 *
0111
1000 *
1010
1100
1001 *
1011
1101
1110 *
1111
```

Здесь нам нужно уже только 15 итераций. Но на практике, даже такая эвристика с отслеживанием последнего бита дает значительный прирост - затрачивается практически в 2 раза меньше итераций.

Известен ли оптимальный порядок для большего множества? Да, но только для 5 (писать его здесь не буду, можете посмотреть в том же комментарии).

Если кто-то подумал "просто захардкодить и все", то нет. Не забывайте, что перед вами сейчас просто битовая маска включенных/исключенных элементов из множества. В реальности, элементы в битовой маске разрозненны. Например, итерация по множеству из 3 элементов `00101001` будет выглядеть так:

```text
00000001
00001000
00001001
00100000
00100001
00101000
00101001
```

Для реализации своего 1-элементного кэша они используют [класс `NeighborhoodCache`](https://github.com/mysql/mysql-server/blob/ff05628a530696bc6851ba6540ac250c7a059aa7/sql/join_optimizer/subgraph_enumeration.h#L163) и прокидывают его почти везде. Его логика проста: перед началом поиска соседей находим дельту множеств (по факту, проверяем, что последний бит выставлен), а в конце сохраняем рассчитанных соседей, но только если не стоит первый бит (его они назвали `taboo bit`).

Как только я понял идею, то переписал этот код себе. Буквально переписал почти слово в слово, только ~~Васю на Петю~~ `taboo` на `forbidden` поменял (чтобы хоть что-то свое было). Код жил так довольно долго, несколько недель. А потом я спохватился - GPLv2!

Код MySQL распространяется под лицензией GPLv2, а учитывая, что я переписал почти все слово в слово (на тот момент, наверное, еще даже не до конца понимая саму идею), то нарушил эту лицензию - мой то проект под MIT, они не совместимы. Тогда я встал перед вопросом - выкинуть эту хорошую оптимизацию и сделать код медленным или оставить, но поменять лицензию на GPLv2. По итогу выбрал первое и это стало началом увлекательного думания на несколько недель - как мне оптимизировать комбинаторику.

### 1-слойный кэш

Передо мной стоит задача - создать оптимизацию алгоритма, но так, чтобы она не была копиркой MySQL (в моем случае, это важный аспект, потому что после нахождения первого решения часто использую только его).

Сама идея ясна - зачем вычислять все множество соседей, если можно просто его дополнять этой дельтой. Нам нужно как-то найти то-ли шаблон, то-ли еще что, что поможет нам обнаружить подобное подмножество.

А что если посмотреть с другой стороны? Действительно, у нашего способа итерирования по подмножествам есть хорошее свойство - верхняя часть (MSB) меняется гораздо реже чем нижняя (LSB). А почему-бы нам не использовать это свойство - просто закэшируем то, что редко меняется!

Но что такое редко меняется? В первой своей идее за эту константу я взял лидирующие `1` - последовательно лидирующих единиц в числе может только увеличиваться, то есть достаточно только подсчитать соседей для этой последовательности, а затем добавлять меняющуюся. Отделить базовую (не меняющуюся) часть мы можем простой битовой маской - мы ведь знаем размер этой части. Последний вопрос: как нам отследить изменение этой части? Но и это не проблема - это ведь двоичная арифметика, просто отслеживаем сколько итераций до следующей новой `1`, а затем делим на 2 и еще ждем.

Хорошая ли это идея? Как подспорье для дальнейших рассуждений да, но на практике эта схема кэширования даст прирост только в конце, когда у нас почти все заполнено единицами. А что там с MSB? А он все также редко меняется - давайте и его закешируем. Только вопрос как? Учитывая, что лидирующая последовательность единиц постоянно растет нам нужно постоянно думать сколько свободного места у нас есть для этой закешированной части.

Вопрос - что даст больший прирост: кэширование лидирующих нулей или MSB? Давайте посчитаем. Для простоты сделаем это наглядно, на том же множестве из 4 элементов.

Для схемы кэширования лидирующих `1` мы имеем следующую схему расчета (2 столбец количество обработанных узлов, а звездочкой пометил места обновления кэша):

```text
0001  1
0010  1
0011  2
0100  1
0101  2
0110  2
0111  3
1000  1  *
1001  1
1010  1
1011  2
1100  1  *
1101  1
1110  1  *
1111  1 
```

Всего 21 узел. На 1 больше чем схема с табу-битом.

Со схемой кэширования MSB надо вначале ответить на вопрос - а что такое MSB, каков его размер? Возьмем мало, будем очень много вычислять, возьмем много будем часто вычислять этот MSB. В принципе, это все можно также вычислить, так как тут та же самая двоичная математика. Но для наглядности, возьмем MSB равный 2:

```text
0001  1
0010  1
0011  2
0100  1  *
0101  1
0110  1
0111  2
1000  1  *
1001  1
1010  1
1011  2
1100  1  *
1101  1
1110  1
1111  2
```

Тут уже 19 элементов - на целых 2 меньше, но это уже лучше. Берем этот подход.

В итоге, мы получаем схему кэширования с 1 элементом - MSB. Далее, эту неизменяемую часть я буду называть base.

Алгоритм работы с ней довольно прост: через каждые $2^{len(MSB)}$ элементов сохраняем в кэш эту базовую часть, а затем просто используем как стартовую точку при расчете соседей.

### 2-слойный кэш

Погодите, мы ведь работаем с множествами, а любое множество можно создать из предыдущего добавлением одного элемента! Например, множество `011010` можно построить из любого `001010`, `010010` или `011000`. Но это также значит, что можно создать текущее множество простым добавлением самого крайнего с начала элемента. Тот же изначальный пример с табу битом - это частный случай, когда мы добавляли первый элемент.

Давайте построим таблицу из 4 элементов и посмотрим, как мы можем создать текущее множество из предыдущего:

```text
0000 <+  <+  <+
   ^  |   |   |
0001  |   |   |
      |   |   |
0010 -+   |   |
   ^      |   |
0011      |   |
          |   |
0100 <+  -+   |
   ^  |       |
0101  |       |
      |       |
0110 -+       |
   ^          |
0111          |
              |
1000 <+  <+  -+
   ^  |   |
1001  |   |
      |   |
1010 -+   |
   ^      |
1011      |
          |
1100 <+  -+
   ^  |
1101  |
      |
1110 -+
   ^
1111
```

Так, мы берем элементы в ячейке под индексом меньше нашей на какую-то степень 2. Вы видите этот паттерн? Я, да - для создания текущего множества мы должны взять вычисленное множество $2^{zeros}$ шагов назад и добавить к нему наш текущий крайний элемент, а этот $zeros$ - это количество текущих лидирующих нулей!

Погодите - так это таблица динамического программирования, для вычисления текущего множества мы используем результат предыдущего вычисления! И еще погодите, но не значит ли это, что для вычисления соседей для каждого из $2^i$ подмножества нам потребуется обработать ровно $2^i$ узлов? Да, значит!

Таким образом все наше множество можно поделить на 2 части: базовую и табличную. Вопроса о размере каждой части не возникает - вторая часть берет то, что осталось. По итогу мы имеем следующий алгоритм:

1. Если итерация делится на $2^{table size}$, то честно рассчитываем всех соседей и сохраняем в `base`.
2. В противном случае:
   1. Берем нижнюю часть номера итерации (битовой маской)
   2. Считаем количество нулей и вычисляем дельту: $2^{zeros}$
   3. Берем соседей родителя: `table[iteration - delta]`
   4. Довычисляем соседей для первого элемента
   5. Сохраняем полученное значение в таблицу

Возникает уже практический вопрос - а сколько мы готовы отдать на эту таблицу? В текущей реализации для хранения множества используется число, поэтому размер каждого множества фиксированный. Значит, для хранения таблицы с $i$ элементами требуется $8 * 2^i = 2^{i + 3}$ байтов. Теперь можно сделать грубые прикидки.

Для хранения множества из 10 элементов, мне потребуется 8Кб на таблицу, но base часть будет хранить соседей  для 54 элементов. Так как LSB меняется чаще, то значит, что через каждые $2^i = 1024$ итерации мне в худшем случае придется проитерироваться по 54 узлам. Если учесть, что многие запросы содержат меньшее число таблиц, то затраты по постоянное вычисление base части не такие уж и большие в сравнении с (пока теоретическим) общим выигрышем в производительности.

### 3-слойный кэш

Итак, мы пришли к идее хранения таблицы вычисленных соседей с постоянным ее дополнением. Неплохо, конечно, но грустно, что в кешэ только 10 узлов - для сложных запросов мы будем постоянно перерасчитывать базовую часть. Да, мы можем сделать размер таблицы настраиваемым, но в любом случае с какого-то момента размер таблицы может стать непозволительно большим, например, уже с 15 элементов потребуется таблица размером 256 Кб. В худшем случае, после нескольких подобных рекурсивных вызовов (например, тот-же `EnumerateCsgRecursive`) память выделенная только под таблицы может составить больше мегабайта. А можно ли как-то еще оптимизировать? Можно. Вернемся практически к началу.

Вся идея кэширования основывалась на дорассчете соседей первым узлом, но как раз таки, когда наступал момент сохранения соседей для дальнейших рассчетов, то мы *не* сохраняли соседей, если в текущем множестве участвует этот первый `taboo` бит. Почему? А потому что это конечная! Соседи созданные в таком множестве никем использоваться больше не будут. За доказательством долго идти не надо - посмотрите на предыдущую схему и увидите, что соседи, вычисленные в нечетных итерациях, никем не используются.

То есть мы со спокойной душой можем не сохранять соседей нечетных итераций. И сколько же такая оптимизация нам сохраняет? Половину, так как ровно половина множеств четна, а другая нечетна. Код, конечно, придется немного доработать, надо учитывать индексацию новой схемы: для получения предыдущего индекса нужно взять не $2^{zeros}$, а $2^{zeros - 1}$ элементов назад.

Подождите, но если мы обрежем первые биты, то останется другая часть, которая имеет похожий паттерн. Что если и ее тоже так оптимизировать? А сколько раз так можно повторить? Не буду утомлять подобными рассуждениями и сразу скажу - я смог применить подобное префиксное сжатие для 4 элементов. Мне потребовалось только 2 дополнительных переменных для расчета текущих соседей. Таким образом, мы приходим к 3-слойной схеме кэширования: base, table, hot (изначально я их назвал well-done, medium и rare).

Алгоритм работы теперь сильно зависит от номера итерации - в зависимости от его значения мы работаем с base, table или hot частью.

Для начала рассмотрим как мы должны обрабатывать hot часть. Она состоит из 4 элементов и главное - паттерн повторяется. Схему обращений мы уже видели, но здесь повторю ее в контексте ее вычисления:

```text
0   0000 <+  <+  <+    quad leader
       ^  |   |   |
1   0001  |   |   |
          |   |   |
2   0010 -+   |   |
       ^      |   |
3   0011      |   |
              |   |
4   0100 <+  -+   |
       ^  |       |
5   0101  |       |
          |       |
6   0110 -+       |
       ^          |
7   0111          |
                  |
8   1000 <+  <+  -+    quad leader
       ^  |   |
9   1001  |   |
          |   |
10  1010 -+   |
       ^      |
11  1011      |
              |
12  1100 <+  -+
       ^  |
13  1101  |
          |
14  1110 -+
       ^
15  1111
```

Все эти 16 элементов мы делим пополам на 2 части, у каждой из которых есть свой лидер - quad leader. По факту, это закэшированные соседи для множества, в котором выставлен только последний бит. Его мы рассчитываем 2 раза: на 0 и 8 итерации.

Далее, мы также используем оптимизацию для нечетных итераций - для них мы специально на каждой итерации сохраняем соседей четных множеств и на следующей (уже нечетной) итерации просто используем готовое значение (то есть сохранять для нечетных ничего не надо).

В итоге у нас остались итерации: 2, 4, 6, 10, 12, 14. Здесь также все просто - можем заметить, что для 2, 6, 10, 14 нужно просто взять соседей предыдущей четной итерации - его мы и так сохраняем для нечетных итераций, но вот 4 и 12 требуют отдельной обработки - в качестве стартовой точки нужно взять quad leader, но и его мы тоже сохраняем.

В итоге мы храним только 2 вычисленные значения соседей: предыдущая четная итерация и quad leader.

Переходим к table части. Изменения коснулись прежде всего расчета индекса - теперь для дельты нужно из количества нулей вычесть 4 (размер hot части): $2^{zeros - 4}$. Но стоит заметить, что когда начинается новая table часть, то, соответственно, и новая hot часть тоже. Поэтому каждый раз после расчета соседей и сохранения этого значения в таблицу, нам нужно очистить состояние hot части, назначить нового quad-leader текущими соседями.

С base частью изменений почти нет. Во-первых, как можно понять из предыдущих шагов, при начале новой base части нам нужно сбросить состояние table части (вычисление таблицы начинается заново), а также и hot части (quad leader текущее вычисленное значение соседей). Но и это еще не все - почему бы нам не использовать тот же трюк с нечетными итерациями? И верно же - если первый бит текущего номера итерации base части равен 1, то мы можем просто довычислить соседей, так же как делали раньше.

Последний вопрос - как это все комбинировать. Здесь надо использовать префикс. Легко увидеть, что:

- каждые $2^{table size}$ итераций обновлять base часть (что в терминах двоичных чисел означает, что первые $i$ битов 0)
- каждые $2^4 = 16$ итераций делать новые записи в таблицу
- каждые $8$ итераций обновлять quad leader в hot части

Алгоритм значительно усложнился, но чего не сделаешь ради оптимизаций. Теперь, таблица занимает не 8Кб, а всего лишь 0.5Кб.

Когда эта идея устаканилась в голове я уже принялся во всю писать код, как вдруг меня осенило.

### Абсолютный O(1) кэш

Я еще раз посмотрел на схему обращений, расписал ее на 5 элементов и заметил то, что я не замечал, но было на виду все время. Вот схема, а справа количество обращений к элементам (для нечетных не писал):

```text
00000 <+  <+  <+  <+    5
    ^  |   |   |   |    
00001  |   |   |   |
       |   |   |   |
00010 -+   |   |   |    1
    ^      |   |   |
00011      |   |   |
           |   |   |
00100 <+  -+   |   |    2
    ^  |       |   |
00101  |       |   |
       |       |   |
00110 -+       |   |    1
    ^          |   |
00111          |   |
               |   |
01000 <+  <+  -+   |    3
    ^  |   |       |
01001  |   |       |
       |   |       |
01010 -+   |       |    1
    ^      |       |
01011      |       |
           |       |
01100 <+  -+       |    2
    ^  |           |
01101  |           |
       |           |
01110 -+           |    1
    ^              |
11111              |
                   |
10000 <+  <+  <+  -+    4  
    ^  |   |   |
10001  |   |   |
       |   |   |
10010 -+   |   |        1
    ^      |   |
10011      |   |
           |   |
10100 <+  -+   |        2
    ^  |       |
10101  |       |
       |       |
10110 -+       |        1
    ^          |
10111          |
               |
11000 <+  <+  -+        3
    ^  |   |
11001  |   |
       |   |
11010 -+   |            1
    ^      |
11011      |
           |
11100 <+  -+            2
    ^  |
11101  |
       |
11110 -+                1
    ^
11111
```

Видите этот паттерн? Если еще нет, то намекну - есть связь между началом множества и количеством обращений. Количество повторных обращений к элементу равно количеству нулей в начале, а дальше это значение вообще не будет использоваться, то есть нам незачем хранить этих соседей. А так как наше итерирование идет только вперед (инкремент), то значит, что мы спокойно можем удалять старые элементы. Для нашей таблицы можно хранить ровно столько элементов, сколько в текущем итерируемом множестве. Так как я представляю множество числом, то мне даже думать не надо - на стеке выделяю массив размером 64 элемента.

Но как правильно ее использовать? Ответ тоже прост. Вспомним то, как мы вычисляем соседей - мы просто берем родительских соседей и дорассчитываем первым элементом. А вот и 2 наблюдение: родительское множество - это наше, но без крайнего бита, например, для `01110` родителем будет `01100`. А в какой ячейке хранятся соседи для `01100`? Правильно под индексом 2, т.к. у него 2 нуля в начале.

Почему мы так можем делать? Доказательство от обратного до банального просто и исходит из свойства алгоритма перебора подмножеств (инкремент).

Нам дана текущая итерация. Мы убираем последний бит, считаем количество нулей и из таблицы берем родительское множество. Я утверждаю, что хранящееся в нем значение принадлежит ровно тому подмножеству, что мы получили убрав первый бит. Представим, что это не так, тогда множество, соседи которого там хранятся, в численном выражении может быть либо больше, либо меньше нашего, но:

- это число точно не может быть больше нашего, так как оно было бы больше и изначального числа, но мы итерируемся строго возрастающим способом, а значит этого числа мы еще не встречали
- не может быть и числом меньше, так как после нескольких итераций мы бы получили очередное число, у которого количество нулей ровно такое же, но в числовом эквиваленте оно больше, и обновили кэш (значение в DP таблице)

Единственный оставшийся вариант - под этим индексом хранятся соседи множества, которое мы получили удалением первого элемента из текущего. Приняв пустое множество за особое значение (или максимальное) и всегда возвращая для него 0, мы также можем утверждать, что и мусора мы получить не можем:

- если текущее множество состоит из 1 элемента, то значит мы перешли в новый разряд, в котором раньше не были раньше - для него мы используем пустое множество (как оговорили только что)
- в противном случае, полученное число мы уже видели и его соседи хранятся в таблице

Вот мы и доказали, что данная схема кэширования корректна.

А теперь, собственно, и сам алгоритм:

1. Создаем DP таблицу, (динамический) массив
2. Начинаем очередную итерацию
3. Из номера итерации убираем первый выставленный бит и считаем количество нулей
4. Из DP таблицы берем элемент под этим индексом
5. Дорассчитываем соседей этим первым битом
6. Сохраняем в таблицу полученное значение

Вот кусок кода, который это все и вычисляет:

```c++
typedef struct SubsetIteratorState
{
    /* Текущее подмножество */
    bitmapword subset;
    /* Переменные состояния для итерирования */
    bitmapword state;
    bitmapword init;
    /* Номер текущей итерации */
    bitmapword iteration;
    /* Кэш соседей */
    bitmapword cached_neighborhood[64];
} SubsetIteratorState;

/* Получение соседей родителя для текущей итарации */
static inline bitmapword
get_parent_neighborhood(DPHypContext *context, SubsetIteratorState *iter_state)
{
    int zero_count;
    bitmapword last_bit_removed;

    last_bit_removed = bmw_difference(iter_state->iteration, bmw_lowest_bit(iter_state->iteration));
    if (bmw_is_empty(last_bit_removed))
    {
        /* Соседей нет */
        return 0;
    }

    zero_count = bmw_rightmost_one_pos(last_bit_removed);
    return iter_state->cached_neighborhood[zero_count];
}

static bitmapword
get_neighbors_iter(DPHypContext *context, bitmapword subgroup,
                    bitmapword excluded, SubsetIteratorState *iter_state)
{
    int i;
    int idx;
    bitmapword neighbors;
    EdgeArray *complex_edges;

    excluded |= subgroup;

    iter_state->iteration++;

    idx = bmw_rightmost_one_pos(iter_state->subset);

    /* База вычисления - соседи родителя текущей итерации */
    neighbors = get_parent_neighborhood(context, iter_state);

    /* Добавляем узлы простых соседей */
    neighbors |= bmw_difference(context->simple_edges[idx], excluded);

    /* Обрабатываем сложные ребра */
    complex_edges = &context->complex_edges[idx];
    i = get_start_index(complex_edges, neighbors | excluded);
    for (; i < complex_edges->size; i++)
    {
        HyperEdge edge = complex_edges->edges[i];
        if ( bmw_is_subset(edge.left, subgroup) &&
            !bmw_overlap(edge.right, neighbors | excluded))
        {
            neighbors |= bmw_lowest_bit(edge.right);
        }
    }

    neighbors = bmw_difference(neighbors, excluded);

    /* Сохраняем соседей */
    if (!IS_ODD(iter_state->iteration))
    {
        int zero_count;

        zero_count = bmw_rightmost_one_pos(iter_state->iteration);
        iter_state->cached_neighborhood[zero_count] = neighbors;
    }

    return neighbors;
}
```

Эту схему также можно чуть-чуть оптимизировать не сохраняя нечетные множества, но это уже микро-оптимизации.

Оптимизация хорошая, но нельзя ли еще добавить оптимизаций? Да, можно. Пример этого есть в коде, который только что показал - индексирование.

## Индексирование ребер

Когда рассказывал про особенности реализации, то упомянул про то, что сортирую сложные ребра. Одна из причин избавление от дубликатов, но есть и другая. Чтобы понять какая, надо посмотреть на некоторые части DPhyp, а конкретно те места, в которых нам необходимо обходить ребра: поиск соседей и определение связи (ребра) между 2 гиперузлами. Если посмотреть на эти места внимательнее, то можно увидеть похожий паттерн, как и в случае с общей идеей кеширования - есть движущиеся детали, а есть постоянные:

- при поиске соседей множество исключенных узлов (`excluded`) фиксированно
- при определении связи между гиперузлами оба гиперузла не меняются

Можно ли как-то использовать это знание? Почему бы и нет. Для начала разберемся с главной проблемой - исключенные узлы.

Проанализировав DPhyp, можно понять, что множество исключенных узлов имеет одинаковую структуру: лидирующие единицы, а затем разрозненные элементы, например, `010110011111` - есть 5 лидирующих 1. Это не случайно, так работает алгоритм - мы не должны смотреть на узлы, которые еще не обрабатывали, поэтому каждый раз при обходе ребер мы проверяем, что никакая часть не пересекается с этими исключенными. Это множество в процессе итерирования может только увеличиться, но не уменьшится, а это значит, что мы заранее можем знать, что какие узлы точно не будут удовлетворять условию, то есть будут пересекаться с этими лидирующими нулями.

Мы можем сделать следующее. Берем все гиперребра и сортируем их по правой части, а для сравнения используем количество лидирующих нулей (или индекс первого элемента, без разницы). Затем, когда приходит время итерироваться, мы вычисляем длину последовательности лидирующих единиц в множестве исключенных и стартовый индекс для итерации ставим таким, чтобы первый элемент правой части ребра был точно больше последнего элемента последовательности единиц.

Если не понятно, покажу на примере. У нас имеется несколько отсортированных гиперребер. Она отсортирована по количеству лидирующих нулей. Справа написал индексы этих ребер для удобства (левая часть не важна, только правая):

```text
[
    xxxxx - 00101    0
    xxxxx - 00111    1
    xxxxx - 00100    2
    xxxxx - 00100    3
    xxxxx - 01100    4
    xxxxx - 10100    5
    xxxxx - 11100    6
    xxxxx - 01000    7
]
```

Теперь мы с легкостью можем понять с какого индекса нам стоит начать итерацию в зависимости от того, какое множество исключенных узлов перед нами:

| `excluded` | стартовый индекс |
| ---------- | ---------------- |
| `00100`    | 0                |
| `00001`    | 2                |
| `11101`    | 2                |
| `10011`    | 2                |
| `00111`    | 7                |
| `01111`    | 8                |

Сразу несколько моментов:

1. Мы можем быть уверен только в размере лидирующих единиц, остальная часть для нас черный ящик. Например, из-за этого в 3 примере итерацию начинаем со 2 индекса, хотя остальная часть видно, что полностью исключена.
2. Для обобщения кода, в случае когда нет подходящих ребер мы можем возвращать длину массива (большое число) и итерирования просто не произойдет

Чтобы понять ее пользу, вспомните, что все ребра в графе двунаправленные, то есть для каждого гиперребра мы создаем 2 пары (поменяли левую и правую часть местами). Поэтому, может так оказаться, что на какой-то узел ссылается очень большое количество таблиц (например, это таблица фактов, а размерностей у нас 100+), а сама эта таблица имеет самый большой индекс, то есть `excluded` будет включать почти все таблицы. В этом случае, нам придется безуспешно проходить по всем сложным ребрам, зная, что это не даст никакого результата.

Хорошо, а как мы будем получать стартовый индекс? Первое что приходит в голову, когда говорят "отсортированный" - бинарный поиск, но не спешите с выводами. Вспомним, что наше пространство "ключей" дискретное - количество лидирующих нулей/единиц. Начинается оно с 0 и может только увеличиваться. А что подходит под это? Массив - под индексом `i` будет хранится первый индекс массива гиперребер, первый элемент правой части (гиперребра) которого не меньше этого `i`.

А что делать с пробелами? Например, в примере после `00111` сразу идет `00100`, без `00010`. Тут мы можем использовать факт, что если я удовлетворяю длине `i`, то буду и длине `i + 1`, так как я точно не буду пересекаться с этим множеством. Простой пример, если я ребро `001100`, то я удовлетворяю индексам `3`, `4`, `5` и т.д. Таким образом, эти пробелы мы заполняем предыдущим значением. Мы по факту будем строить массив и тогда, получение оптимальной стартовой точки будет стоить `O(1)`, то есть буквально ничего (только расходы на расчет количества единиц).

Для ребер из примера, мы можем построить такой индекс (индекс массива ребер справа):

```text
[
    0: 0
    1: 2
    2: 2
    3: 7
    4: 8
    5: 8
]
```

Размер этого индекса зависит только от максимального количества лидирующих `0` во всем массиве ребер. Для примера видно, что я мог бы создать массив только из 4 элементов, а дальше всегда возвращать `8` (как размер массива). Сам этот индекс я назвал `start index`, так как он указывает на индекс для начала итерирования.

Мы научились быстро отсекать ненужные ребра при поиске соседей. Но также по ребрам мы ходим для определения связанности 2 гиперграфов. Можно ли использовать этот индекс и здесь? Да, можно.

2 гиперузла соединены, когда есть гиперребро левая часть которого подмножество левого гиперузла, а правая часть - правого. Гиперузлы на входе никак не меняются - точно также как и множество исключенных. А теперь надо заметить, что правая часть гиперребра точно не будет подмножеством, если в этой части есть элементы, индекс которых меньше, чем наименьший в гиперузле справа. Пример: правая часть гиперребра `001010` никак не будет подмножеством гиперузла `001100` из-за того, что в ребре есть элемент с индексом 2. То есть семантика здесь практически та же, что и в случае исключенного множества - мы должны исключать все ребра, у которых есть элементы меньше наименьшего элемента правого гиперузла.

Для вычисления стартового индекса используется функция `get_start_index`. Для удобства на вход она принимает не готовый индекс, а множество исключенных узлов. Для получения длины последовательности лидирующих единиц я использую битовый трюк - прибавляю один. После этого, последовательность из единиц превратится в последовательность нулей, заканчивающаяся единицей, а вот ее индекс я считать умею. Эта функция также используется при определении связанности 2 гиперузлов - надо просто перед передачей аргумента из множества, представляющего правое гиперребро, вычесть 1, тогда последовательность нулей обратно станет последовательностью единиц, что по факту для целей этого индекса одно и то же.

```c++
static int
get_start_index(EdgeArray *edges, bitmapword excluded)
{
    int index;
    int lowest_bit;

    lowest_bit = bmw_rightmost_one_pos(excluded + 1);

    if (edges->start_idx_size <= lowest_bit)
        return edges->size;

    index = (int)edges->start_idx[lowest_bit];
    return index;
}
```

## Определение сложности запроса

PostgreSQL использует 2 алгоритма: DPsize и GEQO. Причем последний используется если в запросе таблиц больше, чем значение параметра `geqo_threshold`. Но почему именно количество таблиц? А потому что сложность DPsize определяется количеством таблиц - мы безусловно будем рассматривать все возможные комбинации. Но DPhyp другое дело, его сложность - это сложность графа запроса. В оригинальной статье сравниваются производительности алгоритмов на некоторых типах запросов, но они не дают прямой ответ на то, как определять сложность запроса (а может я проглядел). Но зато этот ответ есть в другой статье - ["Adaptive Optimization of Large Join Queries"](https://db.in.tum.de/~radke/papers/hugejoins.pdf).

Эта статья предлагает мета-алгоритм, который комбинируя несколько разных алгоритмов JOIN'а позволяет создать планы запросов с количеством таблиц в несколько тысяч. Но сейчас не об этом, а о DPhyp. Статья предлагает использовать его в простых запросах. Но что такое простой запрос? Например, если в запросе 100 таблиц это не значит, что DPhyp с ним не справится - а если граф запроса представляет простую цепочку, например, все предикаты в форме `Ti.x OP T(i + 1).x`. В такой постановке это просто цепочка, план для которой найти просто. Но вот если это клика (каждый с каждым), то даже 15 таблиц это уже много. Поэтому для DPhyp сложность надо определять не в количестве таблиц, в сложности графа запроса - **количестве связных подграфов** в нем. Авторы предлагают значение в 10000 связных подграфов как предел эффективности запроса. Это соответствует примерно 14 таблицам в клике.

В этой же самой статье не только предлагается эта идея, но также дается и функция для вычисления количества. Посмотрев на нее я понял - она идеально ложится на ту схему кэширования, что описал ранее. Вот собственно эта функция:

```c++
static uint64
count_cc_recursive(DPHypContext *context, bitmapword subgraph, bitmapword excluded,
                   uint64 count, uint64 max, bitmapword base_neighborhood)
{
    SubsetIteratorState subset_iter;
    subset_iterator_init(&subset_iter, base_neighborhood);
    while (subset_iterator_next(&subset_iter))
    {
        bitmapword set;
        bitmapword excluded_ext;
        bitmapword neighborhood;
    
        count++;
        if (count > max)
            break;

        excluded_ext = excluded | base_neighborhood;
        set = subgraph | subset_iter.subset;
        neighborhood = get_neighbors_iter(context, set, excluded_ext, &subset_iter);
        count = count_cc_recursive(context, set, excluded_ext, count, max, neighborhood);
    }

    return count;
}

static uint64
count_cc(DPHypContext *context, uint64 max)
{
    int64 count = 0;
    int rels_count;

    rels_count = list_length(context->initial_rels);
    for (size_t i = 0; i < rels_count; i++)
    {
        bitmapword excluded;
        bitmapword neighborhood;

        count++;
        if (count > max)
            break;

        excluded = bmw_make_b_v(i);
        neighborhood = get_neighbors_base(context, i, excluded);
        count = count_cc_recursive(context, bmw_make_singleton(i), excluded,
                                   count, max, neighborhood);
    }

    return count;
}
```

Названия для функций я оставил те же самые, что и в статье, но адаптировал сигнатуру для поддержки эффективного итерирования по соседям.

Бонус: количество связных подграфов - это размер результирующей DP таблицы. Я использую это значение для ее предварительной аллокации.
